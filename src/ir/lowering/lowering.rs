use std::collections::HashMap;
use std::collections::HashSet;
use crate::frontend::parser::ast::*;
use crate::ir::ir::*;
use crate::common::types::{IrType, StructLayout, CType};

/// Information about a local variable stored in an alloca.
#[derive(Debug, Clone)]
pub(super) struct LocalInfo {
    /// The Value (alloca) holding the address of this local.
    pub alloca: Value,
    /// Element size for arrays (used for pointer arithmetic on subscript).
    /// For non-arrays this is 0.
    pub elem_size: usize,
    /// Whether this is an array (the alloca IS the base address, not a pointer to one).
    pub is_array: bool,
    /// The IR type of the variable (I8 for char, I32 for int, I64 for long, Ptr for pointers).
    pub ty: IrType,
    /// For pointers and arrays, the type of the pointed-to/element type.
    /// Used for correct loads through pointer dereference and subscript.
    pub pointee_type: Option<IrType>,
    /// If this is a struct/union variable, its layout for member access.
    pub struct_layout: Option<StructLayout>,
    /// Whether this variable is a struct (not a pointer to struct).
    pub is_struct: bool,
    /// The total allocation size of this variable (for sizeof).
    pub alloc_size: usize,
    /// For multi-dimensional arrays: stride (in bytes) per dimension level.
    /// E.g., for int a[2][3][4], strides = [48, 16, 4] (row_size, inner_row, elem).
    /// Empty for non-arrays or 1D arrays (use elem_size instead).
    pub array_dim_strides: Vec<usize>,
    /// Full C type for precise multi-level pointer type resolution.
    pub c_type: Option<CType>,
    /// Whether this variable has _Bool type (needs value clamping to 0/1).
    pub is_bool: bool,
    /// For static local variables: the mangled global name. When set, accesses should
    /// emit a fresh GlobalAddr instruction instead of using `alloca`, because the
    /// declaration may be in an unreachable basic block (skipped by goto/switch).
    pub static_global_name: Option<String>,
    /// For VLA function parameters: runtime stride Values per dimension level.
    /// Parallel to `array_dim_strides`. When `Some(value)`, use the runtime Value
    /// instead of the compile-time stride. This supports parameters like
    /// `int m[rows][cols]` where `cols` is a runtime variable.
    pub vla_strides: Vec<Option<Value>>,
    /// For VLA local variables: the runtime Value holding sizeof(this_variable).
    /// Used when sizeof is applied to a VLA local variable.
    pub vla_size: Option<Value>,
}

/// Information about a global variable tracked by the lowerer.
#[derive(Debug, Clone)]
pub(super) struct GlobalInfo {
    /// The IR type of the global variable.
    pub ty: IrType,
    /// Element size for array globals.
    pub elem_size: usize,
    /// Whether this is an array.
    pub is_array: bool,
    /// For pointers and arrays, the type of the pointed-to/element type.
    pub pointee_type: Option<IrType>,
    /// If this is a struct/union variable, its layout for member access.
    pub struct_layout: Option<StructLayout>,
    /// Whether this variable is a struct (not a pointer to struct).
    pub is_struct: bool,
    /// For multi-dimensional arrays: stride per dimension level.
    pub array_dim_strides: Vec<usize>,
    /// Full C type for precise multi-level pointer type resolution.
    pub c_type: Option<CType>,
}

/// Information about a VLA dimension in a function parameter type.
#[derive(Debug)]
struct VlaDimInfo {
    /// Whether this dimension is a VLA (runtime variable).
    is_vla: bool,
    /// The name of the variable providing the dimension (e.g., "cols").
    dim_expr_name: String,
    /// If not VLA, the constant size value.
    const_size: Option<i64>,
    /// The sizeof the element type at this level (for computing strides).
    base_elem_size: usize,
}

/// Represents an lvalue - something that can be assigned to.
/// Contains the address (as an IR Value) where the data resides.
#[derive(Debug, Clone)]
pub(super) enum LValue {
    /// A direct variable: the alloca is the address.
    Variable(Value),
    /// An address computed at runtime (e.g., arr[i], *ptr).
    Address(Value),
}

/// A single level of switch statement context, pushed/popped as switches nest.
#[derive(Debug)]
pub(super) struct SwitchFrame {
    pub end_label: String,
    pub cases: Vec<(i64, String)>,
    pub default_label: Option<String>,
    pub val_alloca: Value,
    pub expr_type: IrType,
}

/// Information about a function typedef (e.g., `typedef int func_t(int, int);`).
/// Used to detect when a declaration like `func_t add;` is a function declaration
/// rather than a variable declaration.
#[derive(Debug, Clone)]
pub(super) struct FunctionTypedefInfo {
    /// The return TypeSpecifier of the function typedef
    pub return_type: TypeSpecifier,
    /// Parameters of the function typedef
    pub params: Vec<ParamDecl>,
    /// Whether the function is variadic
    pub variadic: bool,
}

/// Metadata about known functions (return types, param types, variadic status, etc.).
/// Tracks function signatures so that calls can insert proper casts and ABI handling.
#[derive(Debug, Default)]
pub(super) struct FunctionMeta {
    /// Function name -> return type mapping for inserting narrowing casts after calls.
    pub return_types: HashMap<String, IrType>,
    /// Function name -> parameter types mapping for inserting implicit argument casts.
    pub param_types: HashMap<String, Vec<IrType>>,
    /// Function name -> flags indicating which parameters are _Bool (need normalization to 0/1).
    pub param_bool_flags: HashMap<String, Vec<bool>>,
    /// Function name -> is_variadic flag for calling convention handling.
    pub variadic: HashSet<String>,
    /// Function pointer variable name -> return type mapping.
    pub ptr_return_types: HashMap<String, IrType>,
    /// Function pointer variable name -> parameter types mapping.
    pub ptr_param_types: HashMap<String, Vec<IrType>>,
    /// Function name -> return CType mapping (for pointer-returning functions).
    pub return_ctypes: HashMap<String, CType>,
    /// Functions that return structs > 8 bytes and need hidden sret pointer.
    /// Maps function name to the struct return size.
    pub sret_functions: HashMap<String, usize>,
}

/// Lowers AST to IR (alloca-based, not yet SSA).
pub struct Lowerer {
    pub(super) next_value: u32,
    pub(super) next_label: u32,
    pub(super) next_string: u32,
    pub(super) next_anon_struct: u32,
    /// Counter for unique static local variable names
    pub(super) next_static_local: u32,
    pub(super) module: IrModule,
    // Current function state
    pub(super) current_blocks: Vec<BasicBlock>,
    pub(super) current_instrs: Vec<Instruction>,
    pub(super) current_label: String,
    /// Name of the function currently being lowered (for static local mangling and scoping user labels)
    pub(super) current_function_name: String,
    /// Return type of the function currently being lowered (for narrowing casts on return)
    pub(super) current_return_type: IrType,
    /// Whether the current function returns _Bool (for value clamping on return)
    pub(super) current_return_is_bool: bool,
    // Variable -> alloca mapping with metadata
    pub(super) locals: HashMap<String, LocalInfo>,
    // Global variable tracking (name -> info)
    pub(super) globals: HashMap<String, GlobalInfo>,
    // Set of known function names (to distinguish globals from functions in Identifier)
    pub(super) known_functions: HashSet<String>,
    // Set of already-defined function bodies (to avoid duplicate definitions)
    pub(super) defined_functions: HashSet<String>,
    // Set of function names declared with static (internal) linkage
    pub(super) static_functions: HashSet<String>,
    // Loop context for break/continue
    pub(super) break_labels: Vec<String>,
    pub(super) continue_labels: Vec<String>,
    /// Stack of switch statement contexts (one frame per nesting level).
    pub(super) switch_stack: Vec<SwitchFrame>,
    /// Struct/union layouts indexed by tag name (or anonymous id).
    pub(super) struct_layouts: HashMap<String, StructLayout>,
    /// Enum constant values collected from enum definitions.
    pub(super) enum_constants: HashMap<String, i64>,
    /// Const-qualified local variable values for compile-time evaluation.
    /// Maps variable name -> constant value (for `const int len = 5000;` etc.)
    pub(super) const_local_values: HashMap<String, i64>,
    /// User-defined goto labels mapped to unique IR labels (scoped per function).
    pub(super) user_labels: HashMap<String, String>,
    /// Typedef mappings (name -> underlying TypeSpecifier).
    pub(super) typedefs: HashMap<String, TypeSpecifier>,
    /// Function typedef info (typedef name -> function signature).
    /// Used to detect declarations like `func_t add;` as function declarations.
    pub(super) function_typedefs: HashMap<String, FunctionTypedefInfo>,
    /// Metadata about known functions (signatures, variadic status, etc.)
    pub(super) func_meta: FunctionMeta,
    /// Mapping from bare static local variable names to their mangled global names.
    /// e.g., "x" -> "main.x.0" for `static int x;` inside `main()`.
    pub(super) static_local_names: HashMap<String, String>,
    /// In the current function being lowered, the alloca holding the sret pointer
    /// (hidden first parameter). None if the function does not use sret.
    pub(super) current_sret_ptr: Option<Value>,
    /// CType for each local variable (needed for complex number operations).
    pub(super) var_ctypes: HashMap<String, CType>,
    /// Return CType for known functions (needed for complex function calls).
    pub(super) func_return_ctypes: HashMap<String, CType>,
}

impl Lowerer {
    pub fn new() -> Self {
        Self {
            next_value: 0,
            next_label: 0,
            next_string: 0,
            next_anon_struct: 0,
            next_static_local: 0,
            module: IrModule::new(),
            current_blocks: Vec::new(),
            current_instrs: Vec::new(),
            current_label: String::new(),
            current_function_name: String::new(),
            current_return_type: IrType::I64,
            current_return_is_bool: false,
            locals: HashMap::new(),
            globals: HashMap::new(),
            known_functions: HashSet::new(),
            defined_functions: HashSet::new(),
            break_labels: Vec::new(),
            continue_labels: Vec::new(),
            switch_stack: Vec::new(),
            struct_layouts: HashMap::new(),
            enum_constants: HashMap::new(),
            const_local_values: HashMap::new(),
            user_labels: HashMap::new(),
            typedefs: HashMap::new(),
            function_typedefs: HashMap::new(),
            func_meta: FunctionMeta::default(),
            static_local_names: HashMap::new(),
            static_functions: HashSet::new(),
            current_sret_ptr: None,
            var_ctypes: HashMap::new(),
            func_return_ctypes: HashMap::new(),
        }
    }

    pub fn lower(mut self, tu: &TranslationUnit) -> IrModule {
        // Seed builtin typedefs (matching the parser's pre-seeded typedef names)
        self.seed_builtin_typedefs();
        // Seed known libc math function signatures for correct calling convention
        self.seed_libc_math_functions();

        // Pass 0: Collect all global typedef declarations so that function return
        // types and parameter types that use typedefs can be resolved in pass 1.
        for decl in &tu.decls {
            if let ExternalDecl::Declaration(decl) = decl {
                if decl.is_typedef {
                    for declarator in &decl.declarators {
                        if !declarator.name.is_empty() {
                            // Check if this typedef defines a function type
                            // (e.g., typedef int func_t(int, int);)
                            let has_func_derived = declarator.derived.iter().any(|d|
                                matches!(d, DerivedDeclarator::Function(_, _)));
                            let has_fptr_derived = declarator.derived.iter().any(|d|
                                matches!(d, DerivedDeclarator::FunctionPointer(_, _)));

                            if has_func_derived && !has_fptr_derived {
                                // This is a function typedef like typedef int func_t(int x);
                                // Extract params and variadic from the Function derived
                                if let Some(DerivedDeclarator::Function(params, variadic)) =
                                    declarator.derived.iter().find(|d| matches!(d, DerivedDeclarator::Function(_, _)))
                                {
                                    // Count pointer levels before the Function derived
                                    let ptr_count = declarator.derived.iter()
                                        .take_while(|d| matches!(d, DerivedDeclarator::Pointer))
                                        .count();
                                    let mut return_type = decl.type_spec.clone();
                                    for _ in 0..ptr_count {
                                        return_type = TypeSpecifier::Pointer(Box::new(return_type));
                                    }
                                    self.function_typedefs.insert(declarator.name.clone(), FunctionTypedefInfo {
                                        return_type,
                                        params: params.clone(),
                                        variadic: *variadic,
                                    });
                                }
                            }

                            let mut resolved_type = decl.type_spec.clone();
                            // Apply derived declarators, but collect consecutive Array
                            // dims and apply in reverse for correct multi-dim ordering.
                            let mut i = 0;
                            while i < declarator.derived.len() {
                                match &declarator.derived[i] {
                                    DerivedDeclarator::Pointer => {
                                        resolved_type = TypeSpecifier::Pointer(Box::new(resolved_type));
                                        i += 1;
                                    }
                                    DerivedDeclarator::Array(_) => {
                                        let mut array_sizes: Vec<Option<Box<Expr>>> = Vec::new();
                                        while i < declarator.derived.len() {
                                            if let DerivedDeclarator::Array(size) = &declarator.derived[i] {
                                                array_sizes.push(size.clone());
                                                i += 1;
                                            } else {
                                                break;
                                            }
                                        }
                                        for size in array_sizes.into_iter().rev() {
                                            resolved_type = TypeSpecifier::Array(Box::new(resolved_type), size);
                                        }
                                    }
                                    _ => { i += 1; }
                                }
                            }
                            self.typedefs.insert(declarator.name.clone(), resolved_type);
                        }
                    }
                }
                // Also register struct/union type definitions so sizeof works for typedefs
                self.register_struct_type(&decl.type_spec);
            }
        }

        // First pass: collect all function names, return types, and parameter types
        // so we can distinguish function references from global variable references,
        // insert proper narrowing casts after calls, and insert implicit argument casts.
        for decl in &tu.decls {
            if let ExternalDecl::FunctionDef(func) = decl {
                self.known_functions.insert(func.name.clone());
                if func.is_static {
                    self.static_functions.insert(func.name.clone());
                }
                let ret_ty = self.type_spec_to_ir(&func.return_type);
                self.func_meta.return_types.insert(func.name.clone(), ret_ty);
                // Track CType for pointer-returning functions
                if ret_ty == IrType::Ptr {
                    let ret_ctype = self.type_spec_to_ctype(&func.return_type);
                    self.func_meta.return_ctypes.insert(func.name.clone(), ret_ctype);
                }
                // Detect struct/complex returns > 8 bytes that need sret (hidden pointer) convention
                {
                    let resolved = self.resolve_type_spec(&func.return_type).clone();
                    if matches!(resolved, TypeSpecifier::Struct(_, _, _) | TypeSpecifier::Union(_, _, _)) {
                        let size = self.sizeof_type(&func.return_type);
                        if size > 8 {
                            self.func_meta.sret_functions.insert(func.name.clone(), size);
                        }
                    }
                    // Complex types > 8 bytes also need sret
                    if matches!(resolved, TypeSpecifier::ComplexDouble | TypeSpecifier::ComplexLongDouble) {
                        let size = self.sizeof_type(&func.return_type);
                        self.func_meta.sret_functions.insert(func.name.clone(), size);
                    }
                }
                // Collect parameter types (skip variadic portion)
                // For K&R functions, float params are promoted to double (default argument promotion)
                let param_tys: Vec<IrType> = func.params.iter().map(|p| {
                    let ty = self.type_spec_to_ir(&p.type_spec);
                    if func.is_kr && ty == IrType::F32 {
                        IrType::F64
                    } else {
                        ty
                    }
                }).collect();
                let param_bool_flags: Vec<bool> = func.params.iter().map(|p| {
                    matches!(self.resolve_type_spec(&p.type_spec), TypeSpecifier::Bool)
                }).collect();
                if !func.variadic || !param_tys.is_empty() {
                    self.func_meta.param_types.insert(func.name.clone(), param_tys);
                    self.func_meta.param_bool_flags.insert(func.name.clone(), param_bool_flags);
                }
                if func.variadic {
                    self.func_meta.variadic.insert(func.name.clone());
                }
            }
            // Also detect function declarations (extern prototypes)
            if let ExternalDecl::Declaration(decl) = decl {
                for declarator in &decl.declarators {
                    // Find the Function derived declarator and count preceding Pointer derivations
                    let mut ptr_count = 0;
                    let mut func_info = None;
                    for d in &declarator.derived {
                        match d {
                            DerivedDeclarator::Pointer => ptr_count += 1,
                            DerivedDeclarator::Function(p, v) => {
                                func_info = Some((p, v));
                                break;
                            }
                            _ => {}
                        }
                    }
                    if let Some((params, variadic)) = func_info {
                        self.known_functions.insert(declarator.name.clone());
                        if decl.is_static {
                            self.static_functions.insert(declarator.name.clone());
                        }
                        // Wrap return type with pointer levels from derived declarators
                        let mut ret_ty = self.type_spec_to_ir(&decl.type_spec);
                        if ptr_count > 0 {
                            ret_ty = IrType::Ptr;
                        }
                        self.func_meta.return_types.insert(declarator.name.clone(), ret_ty);
                        // Track CType for pointer-returning functions
                        if ret_ty == IrType::Ptr {
                            let base_ctype = self.type_spec_to_ctype(&decl.type_spec);
                            let ret_ctype = if ptr_count > 0 {
                                let mut ct = base_ctype;
                                for _ in 0..ptr_count {
                                    ct = CType::Pointer(Box::new(ct));
                                }
                                ct
                            } else {
                                base_ctype
                            };
                            self.func_meta.return_ctypes.insert(declarator.name.clone(), ret_ctype);
                        }
                        // Record complex return types for expr_ctype resolution
                        if ptr_count == 0 {
                            let resolved = self.resolve_type_spec(&decl.type_spec);
                            let ret_ct = self.type_spec_to_ctype(&resolved);
                            if ret_ct.is_complex() {
                                self.func_return_ctypes.insert(declarator.name.clone(), ret_ct);
                            }
                        }
                        // Detect struct/complex returns > 8 bytes that need sret
                        if ptr_count == 0 {
                            let resolved = self.resolve_type_spec(&decl.type_spec).clone();
                            if matches!(resolved, TypeSpecifier::Struct(_, _, _) | TypeSpecifier::Union(_, _, _)) {
                                let size = self.sizeof_type(&decl.type_spec);
                                if size > 8 {
                                    self.func_meta.sret_functions.insert(declarator.name.clone(), size);
                                }
                            }
                            // Complex types > 8 bytes also need sret
                            if matches!(resolved, TypeSpecifier::ComplexDouble | TypeSpecifier::ComplexLongDouble) {
                                let size = self.sizeof_type(&decl.type_spec);
                                self.func_meta.sret_functions.insert(declarator.name.clone(), size);
                            }
                        }
                        let param_tys: Vec<IrType> = params.iter().map(|p| {
                            self.type_spec_to_ir(&p.type_spec)
                        }).collect();
                        let param_bool_flags: Vec<bool> = params.iter().map(|p| {
                            matches!(self.resolve_type_spec(&p.type_spec), TypeSpecifier::Bool)
                        }).collect();
                        if !variadic || !param_tys.is_empty() {
                            self.func_meta.param_types.insert(declarator.name.clone(), param_tys);
                            self.func_meta.param_bool_flags.insert(declarator.name.clone(), param_bool_flags);
                        }
                        if *variadic {
                            self.func_meta.variadic.insert(declarator.name.clone());
                        }
                    } else if declarator.derived.is_empty() || !declarator.derived.iter().any(|d|
                        matches!(d, DerivedDeclarator::Function(_, _) | DerivedDeclarator::FunctionPointer(_, _)))
                    {
                        // Check if the base type is a function typedef
                        // (e.g., `func_t add;` where func_t is typedef int func_t(int);)
                        let resolved_name = if let TypeSpecifier::TypedefName(name) = &decl.type_spec {
                            Some(name.clone())
                        } else {
                            None
                        };
                        if let Some(ref tname) = resolved_name {
                            if let Some(fti) = self.function_typedefs.get(tname).cloned() {
                                self.known_functions.insert(declarator.name.clone());
                                let ret_ty = self.type_spec_to_ir(&fti.return_type);
                                self.func_meta.return_types.insert(declarator.name.clone(), ret_ty);
                                if ret_ty == IrType::Ptr {
                                    let ret_ctype = self.type_spec_to_ctype(&fti.return_type);
                                    self.func_meta.return_ctypes.insert(declarator.name.clone(), ret_ctype);
                                }
                                let param_tys: Vec<IrType> = fti.params.iter().map(|p| {
                                    self.type_spec_to_ir(&p.type_spec)
                                }).collect();
                                let param_bool_flags: Vec<bool> = fti.params.iter().map(|p| {
                                    matches!(self.resolve_type_spec(&p.type_spec), TypeSpecifier::Bool)
                                }).collect();
                                if !fti.variadic || !param_tys.is_empty() {
                                    self.func_meta.param_types.insert(declarator.name.clone(), param_tys);
                                    self.func_meta.param_bool_flags.insert(declarator.name.clone(), param_bool_flags);
                                }
                                if fti.variadic {
                                    self.func_meta.variadic.insert(declarator.name.clone());
                                }
                            }
                        }
                    }
                }
            }
        }

        // Second pass: collect all enum constants from the entire AST
        self.collect_all_enum_constants(tu);

        // Third pass: lower everything
        for decl in &tu.decls {
            match decl {
                ExternalDecl::FunctionDef(func) => {
                    self.lower_function(func);
                }
                ExternalDecl::Declaration(decl) => {
                    self.lower_global_decl(decl);
                }
            }
        }
        self.module
    }

    pub(super) fn fresh_value(&mut self) -> Value {
        let v = Value(self.next_value);
        self.next_value += 1;
        v
    }

    pub(super) fn fresh_label(&mut self, prefix: &str) -> String {
        let l = format!(".L{}_{}", prefix, self.next_label);
        self.next_label += 1;
        l
    }

    pub(super) fn emit(&mut self, inst: Instruction) {
        self.current_instrs.push(inst);
    }

    pub(super) fn terminate(&mut self, term: Terminator) {
        let block = BasicBlock {
            label: self.current_label.clone(),
            instructions: std::mem::take(&mut self.current_instrs),
            terminator: term,
        };
        self.current_blocks.push(block);
    }

    pub(super) fn start_block(&mut self, label: String) {
        self.current_label = label;
        self.current_instrs.clear();
    }

    fn lower_function(&mut self, func: &FunctionDef) {
        // Skip duplicate function definitions (can happen with static inline in headers)
        if self.defined_functions.contains(&func.name) {
            return;
        }
        self.defined_functions.insert(func.name.clone());

        self.next_value = 0;
        self.current_blocks.clear();
        self.locals.clear();
        self.static_local_names.clear();
        self.const_local_values.clear();
        self.break_labels.clear();
        self.continue_labels.clear();
        self.user_labels.clear();
        self.current_function_name = func.name.clone();

        let return_type = self.type_spec_to_ir(&func.return_type);
        self.current_return_type = return_type;
        self.current_return_is_bool = matches!(self.resolve_type_spec(&func.return_type), TypeSpecifier::Bool);

        // Record return CType for complex-returning functions
        let ret_ctype = self.type_spec_to_ctype(&self.resolve_type_spec(&func.return_type).clone());
        if ret_ctype.is_complex() {
            self.func_return_ctypes.insert(func.name.clone(), ret_ctype);
        }

        // Check if this function uses sret (returns struct > 8 bytes via hidden pointer)
        let uses_sret = self.func_meta.sret_functions.contains_key(&func.name);

        let mut params: Vec<IrParam> = Vec::new();
        // If sret, prepend hidden pointer parameter
        if uses_sret {
            params.push(IrParam { name: "__sret_ptr".to_string(), ty: IrType::Ptr });
        }
        // For K&R functions, float params are promoted to double (default argument promotion)
        params.extend(func.params.iter().map(|p| {
            let ty = self.type_spec_to_ir(&p.type_spec);
            let ty = if func.is_kr && ty == IrType::F32 { IrType::F64 } else { ty };
            IrParam {
                name: p.name.clone().unwrap_or_default(),
                ty,
            }
        }));

        // Start entry block
        self.start_block("entry".to_string());
        self.current_sret_ptr = None;

        // Allocate params as local variables.
        //
        // For struct/union pass-by-value params, the caller passes a pointer to its struct.
        // We use a two-phase approach:
        // Phase 1: Emit one alloca per param (ptr-sized for struct params, normal for others).
        //          This ensures find_param_alloca(n) returns the nth param's receiving alloca.
        // Phase 2: Emit struct-sized allocas and Memcpy for struct params.

        // Phase 1: one alloca per parameter for receiving the argument register value
        struct StructParamInfo {
            ptr_alloca: Value,
            struct_size: usize,
            struct_layout: Option<StructLayout>,
            param_name: String,
            is_complex: bool,
            c_type: Option<CType>,
        }
        let mut struct_params: Vec<StructParamInfo> = Vec::new();

        // sret_offset: maps IR param index to func.params index (skip hidden sret param)
        let sret_offset: usize = if uses_sret { 1 } else { 0 };

        for (i, param) in params.iter().enumerate() {
            // For sret, index 0 is the hidden sret pointer param
            if uses_sret && i == 0 {
                // Emit alloca for hidden sret pointer, don't register as local
                let alloca = self.fresh_value();
                self.emit(Instruction::Alloca { dest: alloca, ty: IrType::Ptr, size: 8 });
                self.current_sret_ptr = Some(alloca);
                continue;
            }

            let orig_idx = i - sret_offset;  // index into func.params

            if !param.name.is_empty() {
                let is_struct_param = if let Some(orig_param) = func.params.get(orig_idx) {
                    let resolved = self.resolve_type_spec(&orig_param.type_spec);
                    matches!(resolved, TypeSpecifier::Struct(_, _, _) | TypeSpecifier::Union(_, _, _))
                } else {
                    false
                };

                let is_complex_param = if let Some(orig_param) = func.params.get(orig_idx) {
                    let resolved = self.resolve_type_spec(&orig_param.type_spec);
                    matches!(resolved, TypeSpecifier::ComplexFloat | TypeSpecifier::ComplexDouble | TypeSpecifier::ComplexLongDouble)
                } else {
                    false
                };

                // Emit the alloca that receives the argument value from the register
                let alloca = self.fresh_value();
                let ty = param.ty;
                // Use sizeof from TypeSpecifier for correct long double size (16 bytes)
                let param_size = func.params.get(orig_idx)
                    .map(|p| self.sizeof_type(&p.type_spec))
                    .unwrap_or(ty.size())
                    .max(ty.size());
                self.emit(Instruction::Alloca {
                    dest: alloca,
                    ty,
                    size: param_size,
                });

                if is_struct_param || is_complex_param {
                    // Record that we need to create a struct/complex copy for this param
                    let layout = if is_struct_param {
                        func.params.get(orig_idx)
                            .and_then(|p| self.get_struct_layout_for_type(&p.type_spec))
                    } else {
                        None
                    };
                    let struct_size = if is_complex_param {
                        func.params.get(orig_idx)
                            .map(|p| self.sizeof_type(&p.type_spec))
                            .unwrap_or(16)
                    } else {
                        layout.as_ref().map_or(8, |l| l.size)
                    };
                    let param_ctype = if is_complex_param {
                        func.params.get(orig_idx).map(|p| self.type_spec_to_ctype(&p.type_spec))
                    } else {
                        None
                    };
                    struct_params.push(StructParamInfo {
                        ptr_alloca: alloca,
                        struct_size,
                        struct_layout: layout,
                        param_name: param.name.clone(),
                        is_complex: is_complex_param,
                        c_type: param_ctype,
                    });
                } else {
                    // Normal parameter: register as local immediately
                    let elem_size = if ty == IrType::Ptr {
                        func.params.get(orig_idx).map_or(0, |p| self.pointee_elem_size(&p.type_spec))
                    } else { 0 };

                    let pointee_type = if ty == IrType::Ptr {
                        func.params.get(orig_idx).and_then(|p| self.pointee_ir_type(&p.type_spec))
                    } else { None };

                    let struct_layout = if ty == IrType::Ptr {
                        func.params.get(orig_idx).and_then(|p| self.get_struct_layout_for_pointer_param(&p.type_spec))
                    } else { None };

                    let c_type = func.params.get(orig_idx).map(|p| self.type_spec_to_ctype(&p.type_spec));
                    let is_bool = func.params.get(orig_idx).map_or(false, |p| {
                        matches!(self.resolve_type_spec(&p.type_spec), TypeSpecifier::Bool)
                    });

                    // For pointer-to-array params (e.g., int (*)[3] from int arr[N][3]),
                    // compute array_dim_strides so multi-dim subscripts work.
                    let array_dim_strides = if ty == IrType::Ptr {
                        func.params.get(orig_idx).map_or(vec![], |p| self.compute_ptr_array_strides(&p.type_spec))
                    } else { vec![] };

                    self.locals.insert(param.name.clone(), LocalInfo {
                        alloca,
                        elem_size,
                        is_array: false,
                        ty,
                        pointee_type,
                        struct_layout,
                        is_struct: false,
                        alloc_size: param_size,
                        array_dim_strides,
                        c_type,
                        is_bool,
                        static_global_name: None,
                        vla_strides: vec![],
                        vla_size: None,
                    });

                    // For function pointer parameters, register their return type and
                    // parameter types so indirect calls can perform correct argument casts
                    if let Some(p) = func.params.get(orig_idx) {
                        if let Some(ref fptr_params) = p.fptr_params {
                            let ret_ty = self.type_spec_to_ir(&p.type_spec);
                            // Strip the Pointer wrapper: type_spec is Pointer(ReturnType)
                            let ret_ty = match &p.type_spec {
                                TypeSpecifier::Pointer(inner) => self.type_spec_to_ir(inner),
                                _ => ret_ty,
                            };
                            if let Some(ref name) = p.name {
                                self.func_meta.ptr_return_types.insert(name.clone(), ret_ty);
                                let param_tys: Vec<IrType> = fptr_params.iter().map(|fp| {
                                    self.type_spec_to_ir(&fp.type_spec)
                                }).collect();
                                self.func_meta.ptr_param_types.insert(name.clone(), param_tys);
                            }
                        }
                    }
                }
            }
        }

        // Phase 2: For struct params, emit the struct-sized alloca + memcpy
        for sp in struct_params {
            let struct_alloca = self.fresh_value();
            self.emit(Instruction::Alloca {
                dest: struct_alloca,
                ty: IrType::Ptr,
                size: sp.struct_size,
            });

            // Load the incoming pointer from the ptr_alloca (stored by emit_store_params)
            let src_ptr = self.fresh_value();
            self.emit(Instruction::Load {
                dest: src_ptr,
                ptr: sp.ptr_alloca,
                ty: IrType::Ptr,
            });

            // Copy struct data from the caller's struct to our local alloca
            self.emit(Instruction::Memcpy {
                dest: struct_alloca,
                src: src_ptr,
                size: sp.struct_size,
            });

            // Register the struct/complex alloca as the local variable
            self.locals.insert(sp.param_name, LocalInfo {
                alloca: struct_alloca,
                elem_size: 0,
                is_array: false,
                ty: IrType::Ptr,
                pointee_type: None,
                struct_layout: sp.struct_layout,
                is_struct: true,
                alloc_size: sp.struct_size,
                array_dim_strides: vec![],
                c_type: sp.c_type,
                is_bool: false,
                static_global_name: None,
                vla_strides: vec![],
                vla_size: None,
            });
        }

        // VLA stride computation: for pointer-to-array parameters with runtime dimensions
        // (e.g., int m[rows][cols]), compute strides at runtime using the dimension parameters.
        self.compute_vla_param_strides(func);

        // K&R float promotion: for K&R functions with float params (promoted to double for ABI),
        // load the double value, narrow to float, and update the local to use the float alloca.
        if func.is_kr {
            for (i, param) in func.params.iter().enumerate() {
                let declared_ty = self.type_spec_to_ir(&param.type_spec);
                if declared_ty == IrType::F32 {
                    // The param alloca currently holds an F64 (double) value
                    if let Some(local_info) = self.locals.get(&param.name.clone().unwrap_or_default()).cloned() {
                        let f64_alloca = local_info.alloca;
                        // Load the F64 value
                        let f64_val = self.fresh_value();
                        self.emit(Instruction::Load {
                            dest: f64_val,
                            ptr: f64_alloca,
                            ty: IrType::F64,
                        });
                        // Cast F64 -> F32
                        let f32_val = self.fresh_value();
                        self.emit(Instruction::Cast {
                            dest: f32_val,
                            src: Operand::Value(f64_val),
                            from_ty: IrType::F64,
                            to_ty: IrType::F32,
                        });
                        // Create a new F32 alloca
                        let f32_alloca = self.fresh_value();
                        self.emit(Instruction::Alloca {
                            dest: f32_alloca,
                            ty: IrType::F32,
                            size: 4,
                        });
                        // Store F32 value
                        self.emit(Instruction::Store {
                            val: Operand::Value(f32_val),
                            ptr: f32_alloca,
                            ty: IrType::F32,
                        });
                        // Update local to point to F32 alloca
                        let name = param.name.clone().unwrap_or_default();
                        if let Some(local) = self.locals.get_mut(&name) {
                            local.alloca = f32_alloca;
                            local.ty = IrType::F32;
                            local.alloc_size = 4;
                        }
                    }
                }
            }
        }

        // Lower body
        self.lower_compound_stmt(&func.body);

        // If no terminator, add implicit return
        if !self.current_instrs.is_empty() || self.current_blocks.is_empty()
           || !matches!(self.current_blocks.last().map(|b| &b.terminator), Some(Terminator::Return(_)))
        {
            let ret_op = if return_type == IrType::Void {
                None
            } else {
                Some(Operand::Const(IrConst::I32(0)))
            };
            self.terminate(Terminator::Return(ret_op));
        }

        // A function has internal linkage if it was declared static anywhere
        // in the translation unit (C99 6.2.2p5: once declared with internal
        // linkage, all subsequent declarations also have internal linkage).
        let is_static = func.is_static || self.static_functions.contains(&func.name);
        let ir_func = IrFunction {
            name: func.name.clone(),
            return_type,
            params,
            blocks: std::mem::take(&mut self.current_blocks),
            is_variadic: func.variadic,
            is_declaration: false,
            is_static,
            stack_size: 0,
        };
        self.module.functions.push(ir_func);
    }

    /// For pointer-to-array function parameters with VLA (runtime) dimensions,
    /// compute strides at runtime and store them in the LocalInfo.
    /// Example: `void f(int rows, int cols, int m[rows][cols])`
    /// The parameter `m` has type `Pointer(Array(Int, cols))` where `cols` is a runtime variable.
    /// We need to compute stride[0] = cols * sizeof(int) at runtime.
    fn compute_vla_param_strides(&mut self, func: &FunctionDef) {
        // Collect VLA info first, then emit code (avoids borrow issues)
        let mut vla_params: Vec<(String, Vec<VlaDimInfo>)> = Vec::new();

        for param in &func.params {
            let param_name = match &param.name {
                Some(n) => n.clone(),
                None => continue,
            };

            // Check if this parameter is a pointer-to-array with VLA dimensions
            let ts = self.resolve_type_spec(&param.type_spec);
            if let TypeSpecifier::Pointer(inner) = ts {
                let dim_infos = self.collect_vla_dims(inner);
                if dim_infos.iter().any(|d| d.is_vla) {
                    vla_params.push((param_name, dim_infos));
                }
            }
        }

        // Now emit runtime stride computations
        for (param_name, dim_infos) in vla_params {
            let num_strides = dim_infos.len() + 1; // +1 for base element size
            let mut vla_strides: Vec<Option<Value>> = vec![None; num_strides];

            // Compute strides from innermost to outermost
            // For int m[rows][cols]: dims = [cols], base_elem_size = 4
            // stride[1] = 4 (base element)
            // stride[0] = cols * 4 (row stride)
            //
            // For int m[a][b][c]: dims = [b, c], base_elem_size = 4
            // stride[2] = 4
            // stride[1] = c * 4
            // stride[0] = b * c * 4

            // Find the base element size (product of all constant inner dims * scalar size)
            let base_elem_size = dim_infos.last().map_or(1, |d| d.base_elem_size);

            // Start with base element stride
            let mut current_stride: Option<Value> = None;
            let mut current_const_stride = base_elem_size;

            // Process dimensions from innermost to outermost
            for (i, dim_info) in dim_infos.iter().enumerate().rev() {
                if dim_info.is_vla {
                    // Load the VLA dimension variable
                    let dim_val = self.load_vla_dim_value(&dim_info.dim_expr_name);

                    // Compute stride = dim_val * current_stride
                    let stride_val = if let Some(prev) = current_stride {
                        // Runtime stride * runtime dim
                        let result = self.fresh_value();
                        self.emit(Instruction::BinOp {
                            dest: result,
                            op: IrBinOp::Mul,
                            lhs: Operand::Value(dim_val),
                            rhs: Operand::Value(prev),
                            ty: IrType::I64,
                        });
                        result
                    } else {
                        // Constant stride * runtime dim
                        let result = self.fresh_value();
                        self.emit(Instruction::BinOp {
                            dest: result,
                            op: IrBinOp::Mul,
                            lhs: Operand::Value(dim_val),
                            rhs: Operand::Const(IrConst::I64(current_const_stride as i64)),
                            ty: IrType::I64,
                        });
                        result
                    };

                    // stride[i] is the stride for subscript at depth i
                    // which is used when accessing a[i] where a is the array at this level
                    vla_strides[i] = Some(stride_val);
                    current_stride = Some(stride_val);
                    current_const_stride = 0; // no longer constant
                } else {
                    // Constant dimension
                    let const_dim = dim_info.const_size.unwrap_or(1) as usize;
                    if let Some(prev) = current_stride {
                        // Multiply runtime stride by constant dim
                        let result = self.fresh_value();
                        self.emit(Instruction::BinOp {
                            dest: result,
                            op: IrBinOp::Mul,
                            lhs: Operand::Value(prev),
                            rhs: Operand::Const(IrConst::I64(const_dim as i64)),
                            ty: IrType::I64,
                        });
                        vla_strides[i] = Some(result);
                        current_stride = Some(result);
                    } else {
                        current_const_stride *= const_dim;
                        // This level's stride is still compile-time constant
                        // vla_strides[i] remains None (use array_dim_strides)
                    }
                }
            }

            // Update the LocalInfo with VLA strides
            if let Some(local) = self.locals.get_mut(&param_name) {
                local.vla_strides = vla_strides;
            }
        }
    }

    /// Load the value of a VLA dimension variable (a function parameter).
    fn load_vla_dim_value(&mut self, dim_name: &str) -> Value {
        if let Some(info) = self.locals.get(dim_name).cloned() {
            let loaded = self.fresh_value();
            self.emit(Instruction::Load {
                dest: loaded,
                ptr: info.alloca,
                ty: info.ty,
            });
            loaded
        } else {
            // Fallback: use constant 1
            let val = self.fresh_value();
            self.emit(Instruction::Copy {
                dest: val,
                src: Operand::Const(IrConst::I64(1)),
            });
            val
        }
    }

    /// Collect VLA dimension information from a pointer-to-array type.
    /// For `Pointer(Array(Array(Int, c), b))`, returns [{name:"b", is_vla:true}, {name:"c", is_vla:true}]
    fn collect_vla_dims(&self, inner: &TypeSpecifier) -> Vec<VlaDimInfo> {
        let mut dims = Vec::new();
        let mut current = inner;
        loop {
            let resolved = self.resolve_type_spec(current);
            if let TypeSpecifier::Array(elem, size_expr) = resolved {
                let (is_vla, dim_name, const_size) = if let Some(expr) = size_expr {
                    if let Some(val) = self.expr_as_array_size(expr) {
                        (false, String::new(), Some(val))
                    } else {
                        // Non-constant dimension - extract the variable name
                        let name = Self::extract_dim_expr_name(expr);
                        (true, name, None)
                    }
                } else {
                    (false, String::new(), None)
                };

                // Compute base_elem_size for this level
                let base_elem_size = self.sizeof_type(elem);

                dims.push(VlaDimInfo {
                    is_vla,
                    dim_expr_name: dim_name,
                    const_size,
                    base_elem_size,
                });
                current = elem;
            } else {
                break;
            }
        }
        dims
    }

    /// Extract variable name from a VLA dimension expression.
    /// Handles simple cases like Identifier("cols").
    fn extract_dim_expr_name(expr: &Expr) -> String {
        match expr {
            Expr::Identifier(name, _) => name.clone(),
            _ => String::new(),
        }
    }

    fn lower_global_decl(&mut self, decl: &Declaration) {
        // Register any struct/union definitions
        self.register_struct_type(&decl.type_spec);

        // Collect enum constants from top-level enum type declarations
        self.collect_enum_constants(&decl.type_spec);

        // If this is a typedef, register the mapping and skip variable emission
        if decl.is_typedef {
            for declarator in &decl.declarators {
                if !declarator.name.is_empty() {
                    // For pointer typedefs (e.g., typedef int *intptr;), wrap in Pointer
                    // For multi-dim arrays, collect consecutive Array dims and apply
                    // in reverse for correct type nesting.
                    let mut resolved_type = decl.type_spec.clone();
                    let mut i = 0;
                    while i < declarator.derived.len() {
                        match &declarator.derived[i] {
                            DerivedDeclarator::Pointer => {
                                resolved_type = TypeSpecifier::Pointer(Box::new(resolved_type));
                                i += 1;
                            }
                            DerivedDeclarator::Array(_) => {
                                let mut array_sizes: Vec<Option<Box<Expr>>> = Vec::new();
                                while i < declarator.derived.len() {
                                    if let DerivedDeclarator::Array(size) = &declarator.derived[i] {
                                        array_sizes.push(size.clone());
                                        i += 1;
                                    } else {
                                        break;
                                    }
                                }
                                for size in array_sizes.into_iter().rev() {
                                    resolved_type = TypeSpecifier::Array(Box::new(resolved_type), size);
                                }
                            }
                            _ => { i += 1; }
                        }
                    }
                    self.typedefs.insert(declarator.name.clone(), resolved_type);
                }
            }
            return;
        }

        for declarator in &decl.declarators {
            if declarator.name.is_empty() {
                continue; // Skip anonymous declarations (e.g., struct definitions)
            }

            // Skip function declarations (prototypes), but NOT function pointer variables.
            // Function declarations use DerivedDeclarator::Function (e.g., int func(int);
            // or char *func(int);). Function pointer variables use FunctionPointer
            // (e.g., int (*fp)(int) = add;).
            if declarator.derived.iter().any(|d| matches!(d, DerivedDeclarator::Function(_, _)))
                && !declarator.derived.iter().any(|d| matches!(d, DerivedDeclarator::FunctionPointer(_, _)))
                && declarator.init.is_none()
            {
                continue;
            }

            // Skip declarations using function typedefs (e.g., `func_t add;` where
            // func_t is `typedef int func_t(int);`). These declare functions, not variables.
            if declarator.init.is_none() {
                if let TypeSpecifier::TypedefName(tname) = &decl.type_spec {
                    if self.function_typedefs.contains_key(tname) {
                        continue;
                    }
                }
            }

            // extern without initializer: track the type but don't emit a .bss entry
            // (the definition will come from another translation unit)
            if decl.is_extern && declarator.init.is_none() {
                if !self.globals.contains_key(&declarator.name) {
                    let base_ty = self.type_spec_to_ir(&decl.type_spec);
                    let (_, elem_size, is_array, is_pointer, array_dim_strides) = self.compute_decl_info(&decl.type_spec, &declarator.derived);
                    let is_array_of_func_ptrs = is_array && declarator.derived.iter().any(|d|
                        matches!(d, DerivedDeclarator::FunctionPointer(_, _) | DerivedDeclarator::Function(_, _)));
                    let var_ty = if is_pointer || is_array_of_func_ptrs { IrType::Ptr } else { base_ty };
                    let struct_layout = self.get_struct_layout_for_type(&decl.type_spec);
                    let is_struct = struct_layout.is_some() && !is_pointer && !is_array;
                    let pointee_type = self.compute_pointee_type(&decl.type_spec, &declarator.derived);
                    let c_type = Some(self.build_full_ctype(&decl.type_spec, &declarator.derived));
                    self.globals.insert(declarator.name.clone(), GlobalInfo {
                        ty: var_ty,
                        elem_size,
                        is_array,
                        pointee_type,
                        struct_layout,
                        is_struct,
                        array_dim_strides,
                        c_type,
                    });
                }
                continue;
            }

            // If this global already exists (e.g., `extern int a; int a = 0;`),
            // handle tentative definitions and re-declarations correctly.
            if self.globals.contains_key(&declarator.name) {
                if declarator.init.is_none() {
                    // Check if this is a tentative definition (non-extern without init)
                    // that needs to be emitted because only an extern was previously tracked
                    let already_emitted = self.module.globals.iter().any(|g| g.name == declarator.name);
                    if already_emitted {
                        // Already defined in .data/.bss, skip duplicate
                        continue;
                    }
                    // Not yet emitted: this is a tentative definition after an extern declaration.
                    // Fall through to emit it as zero-initialized.
                } else {
                    // Has initializer: remove the previous zero-init/extern global and re-emit with init
                    self.module.globals.retain(|g| g.name != declarator.name);
                }
            }

            let mut base_ty = self.type_spec_to_ir(&decl.type_spec);
            let (mut alloc_size, elem_size, is_array, is_pointer, mut array_dim_strides) = self.compute_decl_info(&decl.type_spec, &declarator.derived);
            // For typedef'd array types (e.g., typedef int a[]; a x = {...}),
            // type_spec_to_ir returns Ptr (array decays to pointer), but we need
            // the element type for correct data emission.
            if is_array && base_ty == IrType::Ptr && !is_pointer {
                if let TypeSpecifier::Array(ref elem, _) = self.resolve_type_spec(&decl.type_spec) {
                    base_ty = self.type_spec_to_ir(elem);
                }
            }
            // For array-of-pointers or array-of-function-pointers, element type is Ptr
            let is_array_of_pointers = is_array && {
                let ptr_pos = declarator.derived.iter().position(|d| matches!(d, DerivedDeclarator::Pointer));
                let arr_pos = declarator.derived.iter().position(|d| matches!(d, DerivedDeclarator::Array(_)));
                matches!((ptr_pos, arr_pos), (Some(pp), Some(ap)) if pp < ap)
            };
            let is_array_of_func_ptrs = is_array && declarator.derived.iter().any(|d|
                matches!(d, DerivedDeclarator::FunctionPointer(_, _) | DerivedDeclarator::Function(_, _)));
            let var_ty = if is_pointer || is_array_of_pointers || is_array_of_func_ptrs { IrType::Ptr } else { base_ty };

            // For unsized arrays (int a[] = {...} or typedef int a[]; a x = {1,2,3}),
            // compute actual size from initializer
            let is_unsized_array = is_array && (
                declarator.derived.iter().any(|d| {
                    matches!(d, DerivedDeclarator::Array(None))
                })
                || matches!(self.resolve_type_spec(&decl.type_spec), TypeSpecifier::Array(_, None))
            );
            if is_unsized_array {
                if let Some(ref init) = declarator.init {
                    match init {
                        Initializer::Expr(expr) => {
                            // Fix alloc size for unsized char arrays initialized with string literals
                            if base_ty == IrType::I8 || base_ty == IrType::U8 {
                                if let Expr::StringLiteral(s, _) = expr {
                                    alloc_size = s.as_bytes().len() + 1;
                                }
                            }
                        }
                        Initializer::List(items) => {
                            let actual_count = self.compute_init_list_array_size_for_char_array(items, base_ty);
                            if elem_size > 0 {
                                alloc_size = actual_count * elem_size;
                                if array_dim_strides.len() == 1 {
                                    array_dim_strides = vec![elem_size];
                                }
                            }
                        }
                    }
                }
            }

            // Determine struct layout for global struct/pointer-to-struct variables
            let struct_layout = self.get_struct_layout_for_type(&decl.type_spec);
            let is_struct = struct_layout.is_some() && !is_pointer && !is_array;

            let actual_alloc_size = if let Some(ref layout) = struct_layout {
                if is_array {
                    alloc_size
                } else {
                    layout.size
                }
            } else if !is_array && !is_pointer {
                // For scalar globals, use the actual C type size (handles long double = 16 bytes)
                let c_size = self.sizeof_type(&decl.type_spec);
                c_size.max(var_ty.size())
            } else {
                alloc_size
            };

            // Extern declarations without initializers: track but don't emit storage
            let is_extern_decl = decl.is_extern && declarator.init.is_none();

            // Determine initializer
            let init = if let Some(ref initializer) = declarator.init {
                self.lower_global_init(initializer, &decl.type_spec, base_ty, is_array, elem_size, actual_alloc_size, &struct_layout, &array_dim_strides)
            } else {
                GlobalInit::Zero
            };

            // Track this global variable
            let pointee_type = self.compute_pointee_type(&decl.type_spec, &declarator.derived);
            let c_type = Some(self.build_full_ctype(&decl.type_spec, &declarator.derived));
            self.globals.insert(declarator.name.clone(), GlobalInfo {
                ty: var_ty,
                elem_size,
                is_array,
                pointee_type,
                struct_layout,
                is_struct,
                array_dim_strides,
                c_type,
            });

            // Use C type alignment for long double (16) instead of IrType::F64 alignment (8)
            let align = {
                let c_align = self.alignof_type(&decl.type_spec);
                if c_align > 0 { c_align.max(var_ty.align()) } else { var_ty.align() }
            };

            let is_static = decl.is_static;

            // For struct initializers emitted as byte arrays, set element type to I8
            // so the backend emits .byte directives for each element.
            // This applies to both single structs and arrays of structs.
            // Detect by checking if the Array init contains I8 constants (byte-serialized struct).
            let global_ty = if matches!(&init, GlobalInit::Array(vals) if !vals.is_empty() && matches!(vals[0], IrConst::I8(_))) {
                IrType::I8
            } else if is_struct && matches!(init, GlobalInit::Array(_)) {
                IrType::I8
            } else {
                var_ty
            };

            // For structs with FAMs, the init byte array may be larger than layout.size.
            // Use the actual init data size if it exceeds the computed alloc size.
            let final_size = match &init {
                GlobalInit::Array(vals) if is_struct && vals.len() > actual_alloc_size => vals.len(),
                _ => actual_alloc_size,
            };

            self.module.globals.push(IrGlobal {
                name: declarator.name.clone(),
                ty: global_ty,
                size: final_size,
                align,
                init,
                is_static,
                is_extern: is_extern_decl,
            });
        }
    }

    /// Lower a global initializer to a GlobalInit value.
    pub(super) fn lower_global_init(
        &mut self,
        init: &Initializer,
        _type_spec: &TypeSpecifier,
        base_ty: IrType,
        is_array: bool,
        elem_size: usize,
        total_size: usize,
        struct_layout: &Option<StructLayout>,
        array_dim_strides: &[usize],
    ) -> GlobalInit {
        // Check if the target type is long double (need to emit as x87 80-bit)
        let is_long_double_target = self.is_type_spec_long_double(_type_spec);

        match init {
            Initializer::Expr(expr) => {
                // Try to evaluate as a constant
                if let Some(val) = self.eval_const_expr(expr) {
                    // Convert integer constants to float if target type is float/double
                    // Use the expression's type for signedness (e.g., unsigned long long -> float)
                    let src_ty = self.get_expr_type(expr);
                    let val = self.coerce_const_to_type_with_src(val, base_ty, src_ty);
                    // If target is long double, promote F64 to LongDouble for proper encoding
                    let val = if is_long_double_target {
                        match val {
                            IrConst::F64(v) => IrConst::LongDouble(v),
                            IrConst::F32(v) => IrConst::LongDouble(v as f64),
                            IrConst::I64(v) => {
                                if src_ty.is_unsigned() {
                                    IrConst::LongDouble((v as u64) as f64)
                                } else {
                                    IrConst::LongDouble(v as f64)
                                }
                            }
                            IrConst::I32(v) => IrConst::LongDouble(v as f64),
                            other => other, // LongDouble already, or other type
                        }
                    } else {
                        val
                    };
                    return GlobalInit::Scalar(val);
                }
                // String literal initializer
                if let Expr::StringLiteral(s, _) = expr {
                    if is_array && (base_ty == IrType::I8 || base_ty == IrType::U8) {
                        // Char array: char s[] = "hello" -> inline the string bytes
                        return GlobalInit::String(s.clone());
                    } else {
                        // Pointer: const char *s = "hello" -> reference .rodata label
                        let label = format!(".Lstr{}", self.next_string);
                        self.next_string += 1;
                        self.module.string_literals.push((label.clone(), s.clone()));
                        return GlobalInit::GlobalAddr(label);
                    }
                }
                // Handle &(compound_literal) at file scope: create anonymous global
                if let Expr::AddressOf(inner, _) = expr {
                    if let Expr::CompoundLiteral(ref cl_type_spec, ref cl_init, _) = inner.as_ref() {
                        return self.create_compound_literal_global(cl_type_spec, cl_init);
                    }
                }
                // Handle (compound_literal) used as struct initializer value
                if let Expr::CompoundLiteral(ref cl_type_spec, ref cl_init, _) = expr {
                    if base_ty == IrType::Ptr {
                        // Pointer: create anonymous global and return address
                        return self.create_compound_literal_global(cl_type_spec, cl_init);
                    }
                }
                // Try to evaluate as a global address expression (e.g., &x, func, arr, &arr[3], &s.field)
                if let Some(addr_init) = self.eval_global_addr_expr(expr) {
                    return addr_init;
                }
                // Complex global initializer: try to evaluate as {real, imag} pair
                {
                    let resolved = self.resolve_type_spec(_type_spec).clone();
                    if matches!(resolved, TypeSpecifier::ComplexFloat | TypeSpecifier::ComplexDouble | TypeSpecifier::ComplexLongDouble) {
                        if let Some(init) = self.eval_complex_global_init(expr, &resolved) {
                            return init;
                        }
                    }
                }
                // Can't evaluate - zero init as fallback
                GlobalInit::Zero
            }
            Initializer::List(items) => {
                // Handle brace-wrapped string literal for char arrays:
                // char c[] = {"hello"} or static char c[] = {"hello"}
                // But NOT for pointer arrays like char *arr[] = {"hello"} where
                // elem_size > base_ty.size() (elem is pointer, base is char).
                let is_char_not_ptr_array = elem_size <= base_ty.size().max(1);
                if is_array && is_char_not_ptr_array && (base_ty == IrType::I8 || base_ty == IrType::U8) {
                    if items.len() == 1 && items[0].designators.is_empty() {
                        if let Initializer::Expr(Expr::StringLiteral(s, _)) = &items[0].init {
                            return GlobalInit::String(s.clone());
                        }
                    }
                }

                if is_array && elem_size > 0 {
                    // For struct arrays, elem_size is the actual struct size (from sizeof_type),
                    // whereas base_ty.size() may return Ptr size (8). Use elem_size for structs.
                    // For long double arrays, elem_size=16 but base_ty=F64 (size=8), so use elem_size.
                    // For pointer arrays (e.g., char *arr[N]), elem_size=8 (pointer) but
                    // base_ty=I8 (char), so use elem_size when it's larger than base_ty.size().
                    let num_elems = if struct_layout.is_some() || is_long_double_target {
                        total_size / elem_size.max(1)
                    } else {
                        let base_type_size = base_ty.size().max(1);
                        if elem_size > base_type_size {
                            total_size / elem_size
                        } else {
                            total_size / base_type_size
                        }
                    };

                    // Array of structs: emit as byte array using struct layout.
                    // But skip byte-serialization if any struct field is a pointer type
                    // (pointers need .quad directives for address relocations).
                    let has_ptr_fields = struct_layout.as_ref().map_or(false, |layout| {
                        layout.fields.iter().any(|f| matches!(f.ty, CType::Pointer(_)))
                    });
                    if let Some(ref layout) = struct_layout {
                        if has_ptr_fields {
                            // Use Compound approach for struct arrays with pointer fields
                            return self.lower_struct_array_with_ptrs(items, layout, num_elems);
                        }
                        let struct_size = layout.size;
                        // For multi-dimensional arrays, elem_size > struct_size (row stride).
                        // Use elem_size as the stride for the outer dimension.
                        let outer_stride = if elem_size > struct_size { elem_size } else { struct_size };
                        let mut bytes = vec![0u8; total_size];
                        let mut current_idx = 0usize;
                        let mut item_idx = 0usize;
                        while item_idx < items.len() {
                            let item = &items[item_idx];
                            // Check for index designator
                            if let Some(Designator::Index(ref idx_expr)) = item.designators.first() {
                                if let Some(idx) = self.eval_const_expr(idx_expr).and_then(|c| c.to_usize()) {
                                    current_idx = idx;
                                }
                            }
                            if current_idx >= num_elems {
                                break;
                            }
                            let base_offset = current_idx * outer_stride;
                            // Check for field designator after index designator: [idx].field = val
                            let field_designator_name = item.designators.iter().find_map(|d| {
                                if let Designator::Field(ref name) = d {
                                    Some(name.clone())
                                } else {
                                    None
                                }
                            });
                            match &item.init {
                                Initializer::List(sub_items) => {
                                    // Check if this is a sub-array (multi-dim array of structs).
                                    // A sub-array means outer_stride > struct_size (multi-dim array)
                                    // AND all sub_items are Lists (each representing a full struct init).
                                    // For 1D arrays where struct fields include sub-struct braces,
                                    // outer_stride == struct_size, so we don't misidentify them.
                                    let is_subarray = outer_stride > struct_size
                                        && !sub_items.is_empty()
                                        && sub_items.iter().all(|si| matches!(&si.init, Initializer::List(_)));
                                    if is_subarray {
                                        // Multi-dimensional: sub_items are struct elements in a row.
                                        // base_offset is the start of this row in the byte buffer.
                                        for (si, sub_item) in sub_items.iter().enumerate() {
                                            let sub_offset = base_offset + si * struct_size;
                                            if sub_offset + struct_size > bytes.len() { break; }
                                            match &sub_item.init {
                                                Initializer::List(inner) => {
                                                    self.write_struct_init_to_bytes(&mut bytes, sub_offset, inner, layout);
                                                }
                                                Initializer::Expr(_) => {
                                                    self.fill_struct_global_bytes(&[sub_item.clone()], layout, &mut bytes, sub_offset);
                                                }
                                            }
                                        }
                                        item_idx += 1;
                                    } else {
                                        // Single struct initializer
                                        self.write_struct_init_to_bytes(&mut bytes, base_offset, sub_items, layout);
                                        item_idx += 1;
                                    }
                                }
                                Initializer::Expr(expr) => {
                                    if let Some(ref fname) = field_designator_name {
                                        // [idx].field = val: write to specific field
                                        if let Some(val) = self.eval_const_expr(expr) {
                                            if let Some(field) = layout.fields.iter().find(|f| &f.name == fname) {
                                                let field_ir_ty = IrType::from_ctype(&field.ty);
                                                self.write_const_to_bytes(&mut bytes, base_offset + field.offset, &val, field_ir_ty);
                                            }
                                        }
                                        item_idx += 1;
                                    } else {
                                        // Flat init: consume items for all fields of this struct
                                        let consumed = self.fill_struct_global_bytes(&items[item_idx..], layout, &mut bytes, base_offset);
                                        item_idx += consumed;
                                    }
                                }
                            }
                            // Only advance current_idx if no field designator (sequential init)
                            if field_designator_name.is_none() {
                                current_idx += 1;
                            }
                        }
                        let values: Vec<IrConst> = bytes.iter().map(|&b| IrConst::I8(b as i8)).collect();
                        return GlobalInit::Array(values);
                    }

                    // Check if any element is an address expression or string literal
                    // (for pointer arrays like char *arr[] or func_ptr arr[])
                    // For multi-dim char arrays (char a[2][4] = {"abc", "xyz"}), string literals
                    // should be inlined as bytes, not treated as address expressions.
                    // Distinguish from char *arr[] by checking array_dim_strides.len() > 1.
                    let is_multidim_char_array = matches!(base_ty, IrType::I8 | IrType::U8)
                        && array_dim_strides.len() > 1;
                    // Also check for pointer arrays (elem_size > base_ty.size())
                    // which indicates char *arr[] or similar pointer-to-char arrays.
                    let is_ptr_array = elem_size > base_ty.size().max(1);
                    let has_addr_exprs = items.iter().any(|item| {
                        // Check direct Expr items for address expressions (original check)
                        if let Initializer::Expr(expr) = &item.init {
                            if matches!(expr, Expr::StringLiteral(_, _)) {
                                return !is_multidim_char_array;
                            }
                            if matches!(expr, Expr::LabelAddr(_, _)) {
                                return true;
                            }
                            if self.eval_const_expr(expr).is_none() && self.eval_global_addr_expr(expr).is_some() {
                                return true;
                            }
                        }
                        // Also recurse into nested lists for string literals (double-brace init)
                        Self::init_contains_addr_expr(item, is_multidim_char_array)
                    }) || (is_ptr_array && !is_multidim_char_array && items.iter().any(|item| {
                        Self::init_contains_string_literal(item)
                    }));

                    if has_addr_exprs {
                        // Use Compound initializer for arrays containing address expressions
                        let mut elements = Vec::with_capacity(num_elems);
                        for item in items {
                            self.collect_compound_init_element(&item.init, &mut elements);
                        }
                        // Zero-fill remaining
                        while elements.len() < num_elems {
                            elements.push(GlobalInit::Zero);
                        }
                        return GlobalInit::Compound(elements);
                    }

                    let zero_val = if is_long_double_target {
                        IrConst::LongDouble(0.0)
                    } else {
                        self.zero_const(base_ty)
                    };
                    let mut values = vec![zero_val; num_elems];
                    // For multi-dim arrays, flatten nested init lists
                    if array_dim_strides.len() > 1 {
                        // For multi-dim arrays, num_elems is outer dimension count,
                        // but we need total scalar elements for the flattened init
                        let innermost_stride = array_dim_strides.last().copied().unwrap_or(1).max(1);
                        let total_scalar_elems = if is_long_double_target {
                            total_size / 16
                        } else {
                            total_size / innermost_stride
                        };
                        let ld_zero = if is_long_double_target {
                            IrConst::LongDouble(0.0)
                        } else {
                            self.zero_const(base_ty)
                        };
                        let mut values_flat = vec![ld_zero; total_scalar_elems];
                        let mut flat = Vec::with_capacity(total_scalar_elems);
                        self.flatten_global_array_init(items, array_dim_strides, base_ty, &mut flat);
                        for (i, v) in flat.into_iter().enumerate() {
                            if i < total_scalar_elems {
                                values_flat[i] = if is_long_double_target {
                                    Self::promote_to_long_double(v)
                                } else {
                                    v
                                };
                            }
                        }
                        return GlobalInit::Array(values_flat);
                    } else {
                        // Support designated initializers: [idx] = val
                        let mut current_idx = 0usize;
                        for item in items {
                            // Check for index designator
                            if let Some(Designator::Index(ref idx_expr)) = item.designators.first() {
                                if let Some(idx) = self.eval_const_expr(idx_expr).and_then(|c| c.to_usize()) {
                                    current_idx = idx;
                                }
                            }
                            if current_idx < num_elems {
                                let val = match &item.init {
                                    Initializer::Expr(expr) => {
                                        let raw = self.eval_const_expr(expr).unwrap_or(self.zero_const(base_ty));
                                        let expr_ty = self.get_expr_type(expr);
                                        self.coerce_const_to_type_with_src(raw, base_ty, expr_ty)
                                    }
                                    Initializer::List(sub_items) => {
                                        // Nested list - flatten
                                        let mut sub_vals = Vec::new();
                                        for sub in sub_items {
                                            self.flatten_global_init_item(&sub.init, base_ty, &mut sub_vals);
                                        }
                                        let raw = sub_vals.into_iter().next().unwrap_or(self.zero_const(base_ty));
                                        raw.coerce_to(base_ty)
                                    }
                                };
                                values[current_idx] = if is_long_double_target {
                                    Self::promote_to_long_double(val)
                                } else {
                                    val
                                };
                            }
                            current_idx += 1;
                        }
                    }
                    return GlobalInit::Array(values);
                }

                // Struct/union initializer list: emit field-by-field constants
                if let Some(ref layout) = struct_layout {
                    return self.lower_struct_global_init(items, layout);
                }

                // Scalar with braces: int x = { 1 };
                // C11 6.7.9: A scalar can be initialized with a single braced expression.
                if !is_array && items.len() >= 1 {
                    if let Initializer::Expr(expr) = &items[0].init {
                        if let Some(val) = self.eval_const_expr(expr) {
                            let expr_ty = self.get_expr_type(expr);
                            return GlobalInit::Scalar(self.coerce_const_to_type_with_src(val, base_ty, expr_ty));
                        }
                        // Try address expression
                        if let Some(addr_init) = self.eval_global_addr_expr(expr) {
                            return addr_init;
                        }
                    }
                }

                // Fallback: try to emit as an array of I32 constants
                // (handles cases like plain `{1, 2, 3}` without type info)
                let mut values = Vec::new();
                for item in items {
                    if let Initializer::Expr(expr) = &item.init {
                        if let Some(val) = self.eval_const_expr(expr) {
                            values.push(val);
                        } else {
                            values.push(IrConst::I32(0));
                        }
                    } else {
                        values.push(IrConst::I32(0));
                    }
                }
                if !values.is_empty() {
                    return GlobalInit::Array(values);
                }
                GlobalInit::Zero
            }
        }
    }

    /// Create an anonymous global for a compound literal at file scope.
    /// Used for: struct S *s = &(struct S){1, 2};
    fn create_compound_literal_global(
        &mut self,
        type_spec: &TypeSpecifier,
        init: &Initializer,
    ) -> GlobalInit {
        let label = format!(".Lcompound_lit_{}", self.next_anon_struct);
        self.next_anon_struct += 1;

        let base_ty = self.type_spec_to_ir(type_spec);
        let struct_layout = self.get_struct_layout_for_type(type_spec);
        let alloc_size = if let Some(ref layout) = struct_layout {
            layout.size
        } else {
            self.sizeof_type(type_spec)
        };

        let align = if let Some(ref layout) = struct_layout {
            layout.align.max(base_ty.align())
        } else {
            base_ty.align()
        };

        let global_init = self.lower_global_init(init, type_spec, base_ty, false, 0, alloc_size, &struct_layout, &[]);

        let global_ty = if matches!(&global_init, GlobalInit::Array(vals) if !vals.is_empty() && matches!(vals[0], IrConst::I8(_))) {
            IrType::I8
        } else if struct_layout.is_some() && matches!(global_init, GlobalInit::Array(_)) {
            IrType::I8
        } else {
            base_ty
        };

        self.module.globals.push(IrGlobal {
            name: label.clone(),
            ty: global_ty,
            size: alloc_size,
            align,
            init: global_init,
            is_static: true, // compound literal globals are local to translation unit
            is_extern: false,
        });

        GlobalInit::GlobalAddr(label)
    }

    /// Promote an IrConst value to LongDouble (16 bytes) for long double array elements.
    fn promote_to_long_double(val: IrConst) -> IrConst {
        match val {
            IrConst::F64(v) => IrConst::LongDouble(v),
            IrConst::F32(v) => IrConst::LongDouble(v as f64),
            IrConst::I64(v) => IrConst::LongDouble(v as f64),
            IrConst::I32(v) => IrConst::LongDouble(v as f64),
            IrConst::I16(v) => IrConst::LongDouble(v as f64),
            IrConst::I8(v) => IrConst::LongDouble(v as f64),
            other => other, // LongDouble already or Zero
        }
    }

    /// Lower a struct initializer list to a GlobalInit::Array of field values.
    /// Emits each field's value at its appropriate position, with padding bytes as zeros.
    /// Supports designated initializers like {.b = 2, .a = 1}.
    /// Check if a type contains pointer elements (either directly or as array elements)
    fn type_has_pointer_elements(ty: &CType) -> bool {
        match ty {
            CType::Pointer(_) => true,
            CType::Array(inner, _) => Self::type_has_pointer_elements(inner),
            _ => false,
        }
    }

    /// Check if an initializer (possibly nested) contains expressions that require
    /// address relocations (string literals, address-of expressions, etc.)
    fn init_has_addr_exprs(&self, init: &Initializer) -> bool {
        match init {
            Initializer::Expr(expr) => {
                matches!(expr, Expr::StringLiteral(_, _))
                    || (self.eval_const_expr(expr).is_none() && self.eval_global_addr_expr(expr).is_some())
            }
            Initializer::List(items) => {
                items.iter().any(|item| self.init_has_addr_exprs(&item.init))
            }
        }
    }

    fn lower_struct_global_init(
        &mut self,
        items: &[InitializerItem],
        layout: &StructLayout,
    ) -> GlobalInit {
        // Check if any field has an address expression (needs relocation).
        // This includes:
        // - String literals initializing pointer fields directly
        // - String literals initializing pointer array fields (flat or braced)
        // - Address-of expressions (&var) initializing pointer fields
        // - Nested initializer lists containing any of the above
        let has_addr_fields = self.struct_init_has_addr_fields(items, layout);

        if has_addr_fields {
            return self.lower_struct_global_init_compound(items, layout);
        }

        // Compute total size including flexible array member data if present
        let total_size = layout.size + self.compute_fam_extra_size(items, layout);
        let mut bytes = vec![0u8; total_size];
        self.fill_struct_global_bytes(items, layout, &mut bytes, 0);

        // Emit as array of I8 (byte) constants
        let values: Vec<IrConst> = bytes.iter().map(|&b| IrConst::I8(b as i8)).collect();
        GlobalInit::Array(values)
    }

    /// Compute extra bytes needed for a flexible array member (FAM) at the end of a struct.
    /// Returns 0 if there is no FAM or no initializer data for it.
    fn compute_fam_extra_size(&self, items: &[InitializerItem], layout: &StructLayout) -> usize {
        if let Some(last_field) = layout.fields.last() {
            if let CType::Array(ref elem_ty, None) = last_field.ty {
                let elem_size = elem_ty.size();
                let last_field_idx = layout.fields.len() - 1;
                let mut current_field_idx = 0usize;
                for (item_idx, item) in items.iter().enumerate() {
                    let field_idx = self.resolve_struct_init_field_idx(item, layout, current_field_idx);
                    if field_idx == last_field_idx {
                        let num_elems = match &item.init {
                            Initializer::List(sub_items) => sub_items.len(),
                            Initializer::Expr(_) => items.len() - item_idx,
                        };
                        return num_elems * elem_size;
                    }
                    if field_idx < layout.fields.len() {
                        current_field_idx = field_idx + 1;
                    }
                }
            }
        }
        0
    }

    /// Check if a struct initializer list contains any fields that require address relocations.
    /// This handles flat init (where multiple items fill an array field), braced init,
    /// and designated init patterns.
    fn struct_init_has_addr_fields(&self, items: &[InitializerItem], layout: &StructLayout) -> bool {
        let mut current_field_idx = 0usize;
        let mut item_idx = 0usize;

        while item_idx < items.len() {
            let item = &items[item_idx];
            let field_idx = self.resolve_struct_init_field_idx(item, layout, current_field_idx);

            if field_idx >= layout.fields.len() {
                // Could be flat init filling into an array field; check if previous field
                // was an array of pointers
                item_idx += 1;
                continue;
            }

            let field_ty = &layout.fields[field_idx].ty;

            match &item.init {
                Initializer::Expr(expr) => {
                    // Direct string literal or address expression
                    if matches!(expr, Expr::StringLiteral(_, _)) {
                        // Check if field is a pointer or array of pointers
                        if Self::type_has_pointer_elements(field_ty) {
                            return true;
                        }
                    }
                    if self.eval_const_expr(expr).is_none() && self.eval_global_addr_expr(expr).is_some() {
                        return true;
                    }
                    // For flat array-of-pointer init, consume remaining items for this field
                    if let CType::Array(elem_ty, Some(arr_size)) = field_ty {
                        if Self::type_has_pointer_elements(elem_ty) {
                            // Check if any of the remaining items for this array have addr exprs
                            for i in 1..*arr_size {
                                let next = item_idx + i;
                                if next >= items.len() { break; }
                                if !items[next].designators.is_empty() { break; }
                                if self.init_has_addr_exprs(&items[next].init) {
                                    return true;
                                }
                            }
                        }
                    }
                }
                Initializer::List(nested_items) => {
                    // Check if the nested list contains addr expressions and the field
                    // is or contains pointer types
                    if Self::type_has_pointer_elements(field_ty) {
                        if self.init_has_addr_exprs(&item.init) {
                            return true;
                        }
                    }
                    // Also check for nested structs containing pointer fields
                    if let Some(nested_layout) = self.get_struct_layout_for_ctype(field_ty) {
                        if self.struct_init_has_addr_fields(nested_items, &nested_layout) {
                            return true;
                        }
                    }
                }
            }

            current_field_idx = field_idx + 1;
            item_idx += 1;
        }
        false
    }

    /// Recursively fill byte buffer for struct global initialization.
    /// Returns the number of initializer items consumed.
    fn fill_struct_global_bytes(
        &self,
        items: &[InitializerItem],
        layout: &StructLayout,
        bytes: &mut [u8],
        base_offset: usize,
    ) -> usize {
        let mut item_idx = 0usize;
        let mut current_field_idx = 0usize;

        while item_idx < items.len() {
            let item = &items[item_idx];

            let designator_name = match item.designators.first() {
                Some(Designator::Field(ref name)) => Some(name.as_str()),
                _ => None,
            };
            // Check for array index designator after field designator: .field[idx]
            let array_start_idx: Option<usize> = if designator_name.is_some() {
                item.designators.iter().find_map(|d| {
                    if let Designator::Index(ref idx_expr) = d {
                        self.eval_const_expr(idx_expr).and_then(|c| c.to_usize())
                    } else {
                        None
                    }
                })
            } else {
                // Check for bare index designator on current field (when field is an array)
                match item.designators.first() {
                    Some(Designator::Index(ref idx_expr)) => {
                        self.eval_const_expr(idx_expr).and_then(|c| c.to_usize())
                    }
                    _ => None,
                }
            };
            let field_idx = match layout.resolve_init_field_idx(designator_name, current_field_idx) {
                Some(idx) => idx,
                None => {
                    if designator_name.is_some() { item_idx += 1; continue; }
                    break;
                }
            };
            let field_layout = &layout.fields[field_idx];
            let field_offset = base_offset + field_layout.offset;

            // Handle nested designators (e.g., .a.j = 2): drill into sub-struct
            let has_nested_designator = item.designators.len() > 1
                && matches!(item.designators.first(), Some(Designator::Field(_)));

            match &field_layout.ty {
                CType::Struct(st) if has_nested_designator => {
                    let sub_layout = StructLayout::for_struct(&st.fields);
                    let sub_item = InitializerItem {
                        designators: item.designators[1..].to_vec(),
                        init: item.init.clone(),
                    };
                    self.fill_struct_global_bytes(&[sub_item], &sub_layout, bytes, field_offset);
                    item_idx += 1;
                }
                CType::Union(st) if has_nested_designator => {
                    let sub_layout = StructLayout::for_union(&st.fields);
                    let sub_item = InitializerItem {
                        designators: item.designators[1..].to_vec(),
                        init: item.init.clone(),
                    };
                    self.fill_struct_global_bytes(&[sub_item], &sub_layout, bytes, field_offset);
                    item_idx += 1;
                }
                CType::Array(elem_ty, Some(arr_size)) if has_nested_designator => {
                    // .field[idx] = val: resolve index and write to byte buffer
                    let elem_size = elem_ty.size();
                    let elem_ir_ty = IrType::from_ctype(elem_ty);
                    let idx = item.designators[1..].iter().find_map(|d| {
                        if let Designator::Index(ref idx_expr) = d {
                            self.eval_const_expr(idx_expr).and_then(|c| c.to_usize())
                        } else {
                            None
                        }
                    }).unwrap_or(0);
                    if idx < *arr_size {
                        let elem_offset = field_offset + idx * elem_size;
                        // Check if there are further nested field designators (e.g., .a[2].b = val)
                        let remaining_field_desigs: Vec<_> = item.designators[1..].iter()
                            .filter(|d| matches!(d, Designator::Field(_)))
                            .cloned()
                            .collect();
                        if !remaining_field_desigs.is_empty() {
                            if let Some(sub_layout) = self.get_struct_layout_for_ctype(elem_ty) {
                                let sub_item = InitializerItem {
                                    designators: remaining_field_desigs,
                                    init: item.init.clone(),
                                };
                                self.fill_struct_global_bytes(&[sub_item], &sub_layout, bytes, elem_offset);
                            }
                        } else if let Initializer::Expr(ref expr) = item.init {
                            let val = self.eval_const_expr(expr).unwrap_or(IrConst::I64(0));
                            self.write_const_to_bytes(bytes, elem_offset, &val, elem_ir_ty);
                        }
                    }
                    item_idx += 1;
                }
                CType::Struct(st) => {
                    let sub_layout = StructLayout::for_struct(&st.fields);
                    match &item.init {
                        Initializer::List(sub_items) => {
                            // Nested braces: recursively fill inner struct
                            self.fill_struct_global_bytes(sub_items, &sub_layout, bytes, field_offset);
                            item_idx += 1;
                        }
                        Initializer::Expr(_) => {
                            // Flat init: consume items for inner struct
                            let consumed = self.fill_struct_global_bytes(&items[item_idx..], &sub_layout, bytes, field_offset);
                            if consumed == 0 { item_idx += 1; } else { item_idx += consumed; }
                        }
                    }
                }
                CType::Union(st) => {
                    let sub_layout = StructLayout::for_union(&st.fields);
                    match &item.init {
                        Initializer::List(sub_items) => {
                            self.fill_struct_global_bytes(sub_items, &sub_layout, bytes, field_offset);
                            item_idx += 1;
                        }
                        Initializer::Expr(_) => {
                            let consumed = self.fill_struct_global_bytes(&items[item_idx..], &sub_layout, bytes, field_offset);
                            if consumed == 0 { item_idx += 1; } else { item_idx += consumed; }
                        }
                    }
                }
                CType::Array(elem_ty, Some(arr_size)) => {
                    let elem_size = elem_ty.size();
                    let elem_ir_ty = IrType::from_ctype(elem_ty);
                    match &item.init {
                        Initializer::List(sub_items) => {
                            // Check for brace-wrapped string literal: { "hello" }
                            if sub_items.len() == 1 && sub_items[0].designators.is_empty() {
                                if let Initializer::Expr(Expr::StringLiteral(s, _)) = &sub_items[0].init {
                                    if matches!(elem_ty.as_ref(), CType::Char | CType::UChar) {
                                        let str_bytes = s.as_bytes();
                                        for (i, &b) in str_bytes.iter().enumerate() {
                                            if i >= *arr_size { break; }
                                            if field_offset + i < bytes.len() {
                                                bytes[field_offset + i] = b;
                                            }
                                        }
                                        // null terminator
                                        if str_bytes.len() < *arr_size && field_offset + str_bytes.len() < bytes.len() {
                                            bytes[field_offset + str_bytes.len()] = 0;
                                        }
                                        item_idx += 1;
                                        current_field_idx = field_idx + 1;
                                        continue;
                                    }
                                }
                            }
                            if matches!(elem_ty.as_ref(), CType::Struct(_) | CType::Union(_)) {
                                // Array of structs: each sub_item is a struct element initializer.
                                // Sub-items may be Lists (braced struct init) or Exprs (flat filling).
                                if let CType::Struct(st) = elem_ty.as_ref() {
                                    let sub_layout = StructLayout::for_struct(&st.fields);
                                    let mut sub_idx = 0usize;
                                    let mut ai = 0usize;
                                    while ai < *arr_size && sub_idx < sub_items.len() {
                                        let elem_offset = field_offset + ai * elem_size;
                                        match &sub_items[sub_idx].init {
                                            Initializer::List(inner_items) => {
                                                self.fill_struct_global_bytes(inner_items, &sub_layout, bytes, elem_offset);
                                                sub_idx += 1;
                                            }
                                            Initializer::Expr(_) => {
                                                let consumed = self.fill_struct_global_bytes(&sub_items[sub_idx..], &sub_layout, bytes, elem_offset);
                                                sub_idx += consumed;
                                            }
                                        }
                                        ai += 1;
                                    }
                                } else if let CType::Union(st) = elem_ty.as_ref() {
                                    let sub_layout = StructLayout::for_union(&st.fields);
                                    let mut sub_idx = 0usize;
                                    for ai in 0..*arr_size {
                                        if sub_idx >= sub_items.len() { break; }
                                        let elem_offset = field_offset + ai * elem_size;
                                        match &sub_items[sub_idx].init {
                                            Initializer::List(inner_items) => {
                                                self.fill_struct_global_bytes(inner_items, &sub_layout, bytes, elem_offset);
                                                sub_idx += 1;
                                            }
                                            Initializer::Expr(_) => {
                                                let consumed = self.fill_struct_global_bytes(&sub_items[sub_idx..], &sub_layout, bytes, elem_offset);
                                                sub_idx += consumed;
                                            }
                                        }
                                    }
                                }
                            } else {
                                // Array of scalars: each sub_item is a scalar
                                // Supports [idx]=val designators within the sub-list
                                let mut ai = 0usize;
                                for sub_item in sub_items.iter() {
                                    // Check for index designator: [idx]=val
                                    if let Some(Designator::Index(ref idx_expr)) = sub_item.designators.first() {
                                        if let Some(idx) = self.eval_const_expr(idx_expr).and_then(|c| c.to_usize()) {
                                            ai = idx;
                                        }
                                    }
                                    if ai >= *arr_size { break; }
                                    let elem_offset = field_offset + ai * elem_size;
                                    if let Initializer::Expr(expr) = &sub_item.init {
                                        let val = self.eval_const_expr(expr).unwrap_or(IrConst::I64(0));
                                        self.write_const_to_bytes(bytes, elem_offset, &val, elem_ir_ty);
                                    } else if let Initializer::List(inner) = &sub_item.init {
                                        // Brace-wrapped scalar: {5}
                                        if let Some(first) = inner.first() {
                                            if let Initializer::Expr(expr) = &first.init {
                                                let val = self.eval_const_expr(expr).unwrap_or(IrConst::I64(0));
                                                self.write_const_to_bytes(bytes, elem_offset, &val, elem_ir_ty);
                                            }
                                        }
                                    }
                                    ai += 1;
                                }
                            }
                            item_idx += 1;
                        }
                        Initializer::Expr(expr) => {
                            // String literal initializer for char array field
                            if let Expr::StringLiteral(s, _) = expr {
                                if matches!(elem_ty.as_ref(), CType::Char | CType::UChar) {
                                    let str_bytes = s.as_bytes();
                                    for (i, &b) in str_bytes.iter().enumerate() {
                                        if i >= *arr_size { break; }
                                        if field_offset + i < bytes.len() {
                                            bytes[field_offset + i] = b;
                                        }
                                    }
                                    // null terminator
                                    if str_bytes.len() < *arr_size && field_offset + str_bytes.len() < bytes.len() {
                                        bytes[field_offset + str_bytes.len()] = 0;
                                    }
                                    item_idx += 1;
                                    current_field_idx = field_idx + 1;
                                    continue;
                                }
                            }
                            // Flat initializer: fill array elements from consecutive items
                            // in the init list. E.g., struct { int a[3]; } x = {1, 2, 3};
                            // The items 1, 2, 3 fill a[0], a[1], a[2] respectively.
                            // If an index designator is present (e.g., .a[1]=val), start from that index.
                            let start_ai = array_start_idx.unwrap_or(0);
                            if matches!(elem_ty.as_ref(), CType::Struct(_) | CType::Union(_)) {
                                // Array of structs: consume items for each struct element
                                if let CType::Struct(st) = elem_ty.as_ref() {
                                    let sub_layout = StructLayout::for_struct(&st.fields);
                                    for ai in start_ai..*arr_size {
                                        if item_idx >= items.len() { break; }
                                        let elem_offset = field_offset + ai * elem_size;
                                        let consumed = self.fill_struct_global_bytes(&items[item_idx..], &sub_layout, bytes, elem_offset);
                                        item_idx += consumed;
                                    }
                                } else {
                                    // Union: take one item per element
                                    for ai in start_ai..*arr_size {
                                        if item_idx >= items.len() { break; }
                                        let elem_offset = field_offset + ai * elem_size;
                                        if let Initializer::Expr(e) = &items[item_idx].init {
                                            let val = self.eval_const_expr(e).unwrap_or(IrConst::I64(0));
                                            self.write_const_to_bytes(bytes, elem_offset, &val, elem_ir_ty);
                                        }
                                        item_idx += 1;
                                    }
                                }
                            } else {
                                // Array of scalars: consume up to arr_size items starting from start_ai
                                let mut consumed = 0usize;
                                let mut ai = start_ai;
                                while ai < *arr_size && (item_idx + consumed) < items.len() {
                                    let cur_item = &items[item_idx + consumed];
                                    // Stop if we hit a designator (targeting a different field)
                                    if !cur_item.designators.is_empty() && consumed > 0 { break; }
                                    if let Initializer::Expr(e) = &cur_item.init {
                                        let val = self.eval_const_expr(e).unwrap_or(IrConst::I64(0));
                                        let elem_offset = field_offset + ai * elem_size;
                                        self.write_const_to_bytes(bytes, elem_offset, &val, elem_ir_ty);
                                        consumed += 1;
                                        ai += 1;
                                    } else {
                                        break;
                                    }
                                }
                                item_idx += consumed.max(1);
                            }
                            // Don't increment item_idx here; it was already advanced in the loop
                            current_field_idx = field_idx + 1;
                            continue;
                        }
                    }
                }
                CType::Array(elem_ty, None) => {
                    // Flexible array member (FAM): int values[];
                    // The byte buffer was already enlarged to accommodate FAM data.
                    let elem_size = elem_ty.size();
                    let elem_ir_ty = IrType::from_ctype(elem_ty);
                    match &item.init {
                        Initializer::List(sub_items) => {
                            for (ai, sub_item) in sub_items.iter().enumerate() {
                                let elem_offset = field_offset + ai * elem_size;
                                if let Initializer::Expr(expr) = &sub_item.init {
                                    let val = self.eval_const_expr(expr).unwrap_or(IrConst::I64(0));
                                    if elem_offset + elem_size <= bytes.len() {
                                        self.write_const_to_bytes(bytes, elem_offset, &val, elem_ir_ty);
                                    }
                                } else if let Initializer::List(inner) = &sub_item.init {
                                    // Brace-wrapped scalar: {5}
                                    if let Some(first) = inner.first() {
                                        if let Initializer::Expr(expr) = &first.init {
                                            let val = self.eval_const_expr(expr).unwrap_or(IrConst::I64(0));
                                            if elem_offset + elem_size <= bytes.len() {
                                                self.write_const_to_bytes(bytes, elem_offset, &val, elem_ir_ty);
                                            }
                                        }
                                    }
                                }
                            }
                            item_idx += 1;
                        }
                        Initializer::Expr(expr) => {
                            // Flat init: fill FAM elements from consecutive items
                            let mut ai = 0usize;
                            let val = self.eval_const_expr(expr).unwrap_or(IrConst::I64(0));
                            let elem_offset = field_offset + ai * elem_size;
                            if elem_offset + elem_size <= bytes.len() {
                                self.write_const_to_bytes(bytes, elem_offset, &val, elem_ir_ty);
                            }
                            ai += 1;
                            item_idx += 1;
                            // Continue consuming items without designators
                            while item_idx < items.len() {
                                let next_item = &items[item_idx];
                                if !next_item.designators.is_empty() { break; }
                                if let Initializer::Expr(e) = &next_item.init {
                                    let val = self.eval_const_expr(e).unwrap_or(IrConst::I64(0));
                                    let elem_offset = field_offset + ai * elem_size;
                                    if elem_offset + elem_size <= bytes.len() {
                                        self.write_const_to_bytes(bytes, elem_offset, &val, elem_ir_ty);
                                    }
                                    ai += 1;
                                    item_idx += 1;
                                } else {
                                    break;
                                }
                            }
                            current_field_idx = field_idx + 1;
                            continue;
                        }
                    }
                }
                _ => {
                    // Scalar field (possibly bitfield)
                    let field_ir_ty = IrType::from_ctype(&field_layout.ty);
                    let val = match &item.init {
                        Initializer::Expr(expr) => {
                            self.eval_const_expr(expr).unwrap_or(IrConst::I64(0))
                        }
                        Initializer::List(sub_items) => {
                            // Scalar with braces: int x = {5};
                            if let Some(first) = sub_items.first() {
                                if let Initializer::Expr(expr) = &first.init {
                                    self.eval_const_expr(expr).unwrap_or(IrConst::I64(0))
                                } else { IrConst::I64(0) }
                            } else { IrConst::I64(0) }
                        }
                    };

                    if let (Some(bit_offset), Some(bit_width)) = (field_layout.bit_offset, field_layout.bit_width) {
                        // Bitfield: pack into the storage unit bytes using read-modify-write
                        self.write_bitfield_to_bytes(bytes, field_offset, &val, field_ir_ty, bit_offset, bit_width);
                    } else {
                        self.write_const_to_bytes(bytes, field_offset, &val, field_ir_ty);
                    }
                    item_idx += 1;
                }
            }
            current_field_idx = field_idx + 1;

            // For unions, only one member can be active. If this was a flat init
            // (no field designator), stop after the first field. Designated inits
            // (.a = 1, .c = 2) are allowed to overwrite - the last designator wins.
            if layout.is_union && designator_name.is_none() {
                break;
            }
        }
        item_idx
    }

    /// Lower a struct global init that contains address expressions.
    /// Emits field-by-field using Compound, with padding bytes between fields.
    /// Handles flat init (where multiple items fill an array-of-pointer field),
    /// braced init, and designated init patterns.
    fn lower_struct_global_init_compound(
        &mut self,
        items: &[InitializerItem],
        layout: &StructLayout,
    ) -> GlobalInit {
        let total_size = layout.size;
        let mut elements: Vec<GlobalInit> = Vec::new();
        let mut current_offset = 0usize;

        // Build a map of field_idx -> list of initializer items.
        // For array fields with flat init, multiple items may map to the same field.
        let mut field_inits: Vec<Vec<&InitializerItem>> = vec![Vec::new(); layout.fields.len()];
        let mut current_field_idx = 0usize;

        let mut item_idx = 0;
        while item_idx < items.len() {
            let item = &items[item_idx];
            let field_idx = self.resolve_struct_init_field_idx(item, layout, current_field_idx);
            if field_idx >= layout.fields.len() {
                item_idx += 1;
                continue;
            }

            let field_ty = &layout.fields[field_idx].ty;

            // Check if this is a flat init filling an array field
            if let CType::Array(_, Some(arr_size)) = field_ty {
                if matches!(&item.init, Initializer::Expr(_)) {
                    // Flat init: consume up to arr_size items for this array field
                    let mut consumed = 0;
                    while consumed < *arr_size && (item_idx + consumed) < items.len() {
                        let cur_item = &items[item_idx + consumed];
                        // Stop if we hit a designator targeting a different field
                        if !cur_item.designators.is_empty() && consumed > 0 {
                            break;
                        }
                        if matches!(&cur_item.init, Initializer::List(_)) && consumed > 0 {
                            break;
                        }
                        field_inits[field_idx].push(cur_item);
                        consumed += 1;
                    }
                    item_idx += consumed;
                    current_field_idx = field_idx + 1;
                    let has_designator = !item.designators.is_empty();
                    if layout.is_union && !has_designator { break; }
                    continue;
                }
            }

            field_inits[field_idx].push(item);
            current_field_idx = field_idx + 1;
            item_idx += 1;
            let has_designator = !item.designators.is_empty();
            if layout.is_union && !has_designator { break; }
        }

        for fi in 0..layout.fields.len() {
            let field_offset = layout.fields[fi].offset;
            let field_size = layout.fields[fi].ty.size();
            let field_is_pointer = matches!(layout.fields[fi].ty, CType::Pointer(_));

            // Emit padding before this field
            if field_offset > current_offset {
                let pad = field_offset - current_offset;
                for _ in 0..pad {
                    elements.push(GlobalInit::Scalar(IrConst::I8(0)));
                }
                current_offset = field_offset;
            }

            let inits = &field_inits[fi];
            if inits.is_empty() {
                // No initializer for this field - zero fill
                for _ in 0..field_size {
                    elements.push(GlobalInit::Scalar(IrConst::I8(0)));
                }
            } else if inits.len() == 1 {
                let item = inits[0];
                // Check if this is a designated init for an array-of-pointer field
                // e.g., .a[1] = "abc" where a is char *a[3]
                let has_array_idx_designator = item.designators.iter().any(|d| matches!(d, Designator::Index(_)));
                if has_array_idx_designator {
                    if let CType::Array(elem_ty, Some(arr_size)) = &layout.fields[fi].ty {
                        if Self::type_has_pointer_elements(elem_ty) {
                            // Designated init for pointer array element
                            self.emit_compound_ptr_array_designated_init(
                                &mut elements, &[item], elem_ty, *arr_size);
                        } else {
                            // Non-pointer array with designator - use byte-level approach
                            self.emit_compound_field_init(&mut elements, &item.init, &layout.fields[fi].ty, field_size, field_is_pointer);
                        }
                    } else {
                        self.emit_compound_field_init(&mut elements, &item.init, &layout.fields[fi].ty, field_size, field_is_pointer);
                    }
                } else {
                    self.emit_compound_field_init(&mut elements, &item.init, &layout.fields[fi].ty, field_size, field_is_pointer);
                }
            } else {
                // Multiple items for this field (flat array init)
                self.emit_compound_flat_array_init(&mut elements, inits, &layout.fields[fi].ty, field_size);
            }
            current_offset += field_size;
        }

        // Trailing padding
        while current_offset < total_size {
            elements.push(GlobalInit::Scalar(IrConst::I8(0)));
            current_offset += 1;
        }

        GlobalInit::Compound(elements)
    }

    /// Emit a single field initializer in compound (relocation-aware) mode.
    fn emit_compound_field_init(
        &mut self,
        elements: &mut Vec<GlobalInit>,
        init: &Initializer,
        field_ty: &CType,
        field_size: usize,
        field_is_pointer: bool,
    ) {
        match init {
            Initializer::Expr(expr) => {
                if let Expr::StringLiteral(s, _) = expr {
                    if field_is_pointer {
                        // String literal initializing a pointer field:
                        // create a .rodata string entry and emit GlobalAddr
                        let label = format!(".Lstr{}", self.next_string);
                        self.next_string += 1;
                        self.module.string_literals.push((label.clone(), s.clone()));
                        elements.push(GlobalInit::GlobalAddr(label));
                    } else {
                        // String literal initializing a char array field
                        let s_bytes = s.as_bytes();
                        for (i, &b) in s_bytes.iter().enumerate() {
                            if i >= field_size { break; }
                            elements.push(GlobalInit::Scalar(IrConst::I8(b as i8)));
                        }
                        // null terminator + remaining zero fill
                        for _ in s_bytes.len()..field_size {
                            elements.push(GlobalInit::Scalar(IrConst::I8(0)));
                        }
                    }
                } else if let Some(val) = self.eval_const_expr(expr) {
                    // Scalar constant - emit as bytes
                    self.push_const_as_bytes(elements, &val, field_size);
                } else if let Some(addr_init) = self.eval_global_addr_expr(expr) {
                    // Address expression - emit as relocation
                    elements.push(addr_init);
                } else {
                    // Unknown - zero fill
                    for _ in 0..field_size {
                        elements.push(GlobalInit::Scalar(IrConst::I8(0)));
                    }
                }
            }
            Initializer::List(nested_items) => {
                // Check if this is an array of pointers
                if let CType::Array(elem_ty, Some(arr_size)) = field_ty {
                    if Self::type_has_pointer_elements(elem_ty) {
                        // Array of pointers: emit each element as a GlobalAddr or zero
                        self.emit_compound_ptr_array_init(elements, nested_items, elem_ty, *arr_size);
                        return;
                    }
                }

                // Check if nested struct has pointer fields
                let field_ty_clone = field_ty.clone();
                if let Some(nested_layout) = self.get_struct_layout_for_ctype(&field_ty_clone) {
                    if self.struct_init_has_addr_fields(nested_items, &nested_layout) {
                        // Recursively handle nested struct with address fields
                        let nested = self.lower_struct_global_init_compound(nested_items, &nested_layout);
                        // Flatten nested Compound into our elements
                        if let GlobalInit::Compound(nested_elems) = nested {
                            elements.extend(nested_elems);
                        } else {
                            // Shouldn't happen, but zero-fill as fallback
                            for _ in 0..field_size {
                                elements.push(GlobalInit::Scalar(IrConst::I8(0)));
                            }
                        }
                        return;
                    }
                }

                // No address fields - serialize to bytes
                let mut bytes = vec![0u8; field_size];
                if let Some(nested_layout) = self.get_struct_layout_for_ctype(&field_ty_clone) {
                    self.fill_struct_global_bytes(nested_items, &nested_layout, &mut bytes, 0);
                } else {
                    // Simple array or scalar list
                    let mut byte_offset = 0;
                    let elem_ir_ty = match &field_ty_clone {
                        CType::Array(inner, _) => IrType::from_ctype(inner),
                        other => IrType::from_ctype(other),
                    };
                    let elem_size = elem_ir_ty.size().max(1);
                    for ni in nested_items {
                        if byte_offset >= field_size { break; }
                        if let Initializer::Expr(ref e) = ni.init {
                            if let Some(val) = self.eval_const_expr(e) {
                                let e_ty = self.get_expr_type(e);
                                let val = self.coerce_const_to_type_with_src(val, elem_ir_ty, e_ty);
                                self.write_const_to_bytes(&mut bytes, byte_offset, &val, elem_ir_ty);
                            }
                        }
                        byte_offset += elem_size;
                    }
                }
                for b in &bytes {
                    elements.push(GlobalInit::Scalar(IrConst::I8(*b as i8)));
                }
            }
        }
    }

    /// Emit an array-of-pointers field from a braced initializer list.
    /// Each element is either a GlobalAddr (for string literals / address expressions)
    /// or zero-filled (for missing elements).
    fn emit_compound_ptr_array_init(
        &mut self,
        elements: &mut Vec<GlobalInit>,
        items: &[InitializerItem],
        elem_ty: &CType,
        arr_size: usize,
    ) {
        let ptr_size = 8; // 64-bit pointers
        let mut ai = 0usize;

        for item in items {
            if ai >= arr_size { break; }

            // Handle index designator: [idx] = val
            if let Some(Designator::Index(ref idx_expr)) = item.designators.first() {
                if let Some(idx) = self.eval_const_expr(idx_expr).and_then(|c| c.to_usize()) {
                    // Zero-fill skipped elements
                    while ai < idx && ai < arr_size {
                        for _ in 0..ptr_size {
                            elements.push(GlobalInit::Scalar(IrConst::I8(0)));
                        }
                        ai += 1;
                    }
                }
            }
            if ai >= arr_size { break; }

            if let Initializer::Expr(ref expr) = item.init {
                if let Expr::StringLiteral(s, _) = expr {
                    let label = format!(".Lstr{}", self.next_string);
                    self.next_string += 1;
                    self.module.string_literals.push((label.clone(), s.clone()));
                    elements.push(GlobalInit::GlobalAddr(label));
                } else if let Some(addr_init) = self.eval_global_addr_expr(expr) {
                    elements.push(addr_init);
                } else if let Some(val) = self.eval_const_expr(expr) {
                    self.push_const_as_bytes(elements, &val, ptr_size);
                } else {
                    // zero
                    for _ in 0..ptr_size {
                        elements.push(GlobalInit::Scalar(IrConst::I8(0)));
                    }
                }
            } else {
                // Nested list - zero fill this element
                for _ in 0..ptr_size {
                    elements.push(GlobalInit::Scalar(IrConst::I8(0)));
                }
            }
            ai += 1;
        }

        // Zero-fill remaining elements
        while ai < arr_size {
            for _ in 0..ptr_size {
                elements.push(GlobalInit::Scalar(IrConst::I8(0)));
            }
            ai += 1;
        }
    }

    /// Emit a designated initializer for a pointer array field.
    /// Handles cases like `.a[1] = "abc"` where a is `char *a[3]`.
    /// The items may have field+index designators; we extract the index from the designators.
    fn emit_compound_ptr_array_designated_init(
        &mut self,
        elements: &mut Vec<GlobalInit>,
        items: &[&InitializerItem],
        elem_ty: &CType,
        arr_size: usize,
    ) {
        let ptr_size = 8; // 64-bit pointers
        // Build a sparse map of which indices are initialized
        let mut index_inits: Vec<Option<&Initializer>> = vec![None; arr_size];

        for item in items {
            // Find the Index designator (may be after a Field designator)
            let idx = item.designators.iter().find_map(|d| {
                if let Designator::Index(ref idx_expr) = d {
                    self.eval_const_expr(idx_expr).and_then(|c| c.to_usize())
                } else {
                    None
                }
            }).unwrap_or(0);

            if idx < arr_size {
                index_inits[idx] = Some(&item.init);
            }
        }

        // Emit each element
        for ai in 0..arr_size {
            if let Some(init) = index_inits[ai] {
                if let Initializer::Expr(ref expr) = init {
                    if let Expr::StringLiteral(s, _) = expr {
                        let label = format!(".Lstr{}", self.next_string);
                        self.next_string += 1;
                        self.module.string_literals.push((label.clone(), s.clone()));
                        elements.push(GlobalInit::GlobalAddr(label));
                    } else if let Some(addr_init) = self.eval_global_addr_expr(expr) {
                        elements.push(addr_init);
                    } else if let Some(val) = self.eval_const_expr(expr) {
                        self.push_const_as_bytes(elements, &val, ptr_size);
                    } else {
                        for _ in 0..ptr_size {
                            elements.push(GlobalInit::Scalar(IrConst::I8(0)));
                        }
                    }
                } else {
                    for _ in 0..ptr_size {
                        elements.push(GlobalInit::Scalar(IrConst::I8(0)));
                    }
                }
            } else {
                // Uninitialized element - zero fill
                for _ in 0..ptr_size {
                    elements.push(GlobalInit::Scalar(IrConst::I8(0)));
                }
            }
        }
    }

    /// Emit a flat array init for a field that has multiple items (flat init style).
    /// E.g., struct { char *s[2]; } x = { "abc", "def" };
    fn emit_compound_flat_array_init(
        &mut self,
        elements: &mut Vec<GlobalInit>,
        inits: &[&InitializerItem],
        field_ty: &CType,
        field_size: usize,
    ) {
        let (elem_ty, arr_size) = match field_ty {
            CType::Array(inner, Some(size)) => (inner.as_ref(), *size),
            _ => {
                // Not an array - just use first item
                if let Some(first) = inits.first() {
                    let field_is_pointer = matches!(field_ty, CType::Pointer(_));
                    self.emit_compound_field_init(elements, &first.init, field_ty, field_size, field_is_pointer);
                } else {
                    for _ in 0..field_size {
                        elements.push(GlobalInit::Scalar(IrConst::I8(0)));
                    }
                }
                return;
            }
        };

        let elem_is_pointer = Self::type_has_pointer_elements(elem_ty);
        let elem_size = elem_ty.size();
        let ptr_size = 8; // 64-bit

        let mut ai = 0usize;
        for item in inits {
            if ai >= arr_size { break; }

            if let Initializer::Expr(ref expr) = item.init {
                if elem_is_pointer {
                    if let Expr::StringLiteral(s, _) = expr {
                        let label = format!(".Lstr{}", self.next_string);
                        self.next_string += 1;
                        self.module.string_literals.push((label.clone(), s.clone()));
                        elements.push(GlobalInit::GlobalAddr(label));
                    } else if let Some(addr_init) = self.eval_global_addr_expr(expr) {
                        elements.push(addr_init);
                    } else if let Some(val) = self.eval_const_expr(expr) {
                        self.push_const_as_bytes(elements, &val, ptr_size);
                    } else {
                        for _ in 0..ptr_size {
                            elements.push(GlobalInit::Scalar(IrConst::I8(0)));
                        }
                    }
                } else {
                    if let Some(val) = self.eval_const_expr(expr) {
                        self.push_const_as_bytes(elements, &val, elem_size);
                    } else {
                        for _ in 0..elem_size {
                            elements.push(GlobalInit::Scalar(IrConst::I8(0)));
                        }
                    }
                }
            } else {
                // Nested list - zero fill element
                for _ in 0..elem_size {
                    elements.push(GlobalInit::Scalar(IrConst::I8(0)));
                }
            }
            ai += 1;
        }

        // Zero-fill remaining elements
        while ai < arr_size {
            for _ in 0..elem_size {
                elements.push(GlobalInit::Scalar(IrConst::I8(0)));
            }
            ai += 1;
        }
    }

    /// Push a constant value as individual bytes into a compound init element list.
    fn push_const_as_bytes(&self, elements: &mut Vec<GlobalInit>, val: &IrConst, size: usize) {
        let mut bytes = Vec::with_capacity(size);
        val.push_le_bytes(&mut bytes, size);
        for b in bytes {
            elements.push(GlobalInit::Scalar(IrConst::I8(b as i8)));
        }
    }

    /// Resolve which struct field a positional or designated initializer targets.
    fn resolve_struct_init_field_idx(
        &self,
        item: &InitializerItem,
        layout: &StructLayout,
        current_field_idx: usize,
    ) -> usize {
        let designator_name = match item.designators.first() {
            Some(Designator::Field(ref name)) => Some(name.as_str()),
            _ => None,
        };
        layout.resolve_init_field_idx(designator_name, current_field_idx)
            .unwrap_or(current_field_idx)
    }

    /// Write an initializer item to a byte buffer at the given offset.
    fn write_init_item_to_bytes(&self, bytes: &mut [u8], offset: usize, init: &Initializer, field_ty: &CType) {
        match init {
            Initializer::Expr(expr) => {
                let val = self.eval_const_expr(expr).unwrap_or(IrConst::I64(0));
                let field_ir_ty = IrType::from_ctype(field_ty);
                self.write_const_to_bytes(bytes, offset, &val, field_ir_ty);
            }
            Initializer::List(sub_items) => {
                // Try struct/union layout first
                if let Some(sub_layout) = self.get_struct_layout_for_ctype(field_ty) {
                    self.write_struct_init_to_bytes(bytes, offset, sub_items, &sub_layout);
                } else if let CType::Array(elem_ty, count) = field_ty {
                    let elem_size = elem_ty.size();
                    for (idx, sub_item) in sub_items.iter().enumerate() {
                        if count.map_or(false, |c| idx >= c) { break; }
                        if let Initializer::Expr(expr) = &sub_item.init {
                            let val = self.eval_const_expr(expr).unwrap_or(IrConst::I64(0));
                            let elem_ir_ty = IrType::from_ctype(elem_ty);
                            self.write_const_to_bytes(bytes, offset + idx * elem_size, &val, elem_ir_ty);
                        }
                    }
                } else {
                    // Scalar in braces
                    if let Some(first) = sub_items.first() {
                        if let Initializer::Expr(expr) = &first.init {
                            let val = self.eval_const_expr(expr).unwrap_or(IrConst::I64(0));
                            let field_ir_ty = IrType::from_ctype(field_ty);
                            self.write_const_to_bytes(bytes, offset, &val, field_ir_ty);
                        }
                    }
                }
            }
        }
    }

    /// Write an IrConst value to a byte buffer at the given offset using the field's IR type.
    fn write_const_to_bytes(&self, bytes: &mut [u8], offset: usize, val: &IrConst, ty: IrType) {
        let coerced = val.coerce_to(ty);
        let size = ty.size();
        let mut le_buf = Vec::with_capacity(size);
        coerced.push_le_bytes(&mut le_buf, size);
        for (i, &b) in le_buf.iter().enumerate() {
            if offset + i < bytes.len() {
                bytes[offset + i] = b;
            }
        }
    }

    /// Write a bitfield value into a byte buffer at the given offset.
    /// Uses read-modify-write to pack the value at the correct bit position.
    fn write_bitfield_to_bytes(&self, bytes: &mut [u8], offset: usize, val: &IrConst, ty: IrType, bit_offset: u32, bit_width: u32) {
        let int_val = val.to_u64().unwrap_or(0);

        let size = ty.size();
        let mask = if bit_width >= 64 { u64::MAX } else { (1u64 << bit_width) - 1 };
        let field_val = (int_val & mask) << bit_offset;
        let clear_mask = !(mask << bit_offset);

        // Read current storage unit value (little-endian)
        let mut current = 0u64;
        for i in 0..size {
            if offset + i < bytes.len() {
                current |= (bytes[offset + i] as u64) << (i * 8);
            }
        }

        // Modify: clear field bits and OR in new value
        let new_val = (current & clear_mask) | field_val;

        // Write back (little-endian)
        let le = new_val.to_le_bytes();
        for i in 0..size {
            if offset + i < bytes.len() {
                bytes[offset + i] = le[i];
            }
        }
    }

    /// Write a struct initializer list to a byte buffer at the given base offset.
    /// Handles nested struct fields recursively.
    fn write_struct_init_to_bytes(
        &self,
        bytes: &mut [u8],
        base_offset: usize,
        items: &[InitializerItem],
        layout: &StructLayout,
    ) {
        let mut current_field_idx = 0usize;
        for item in items {
            let designator_name = match item.designators.first() {
                Some(Designator::Field(ref name)) => Some(name.as_str()),
                _ => None,
            };
            let field_idx = match layout.resolve_init_field_idx(designator_name, current_field_idx) {
                Some(idx) => idx,
                None => break,
            };

            let field_layout = &layout.fields[field_idx];
            let field_offset = base_offset + field_layout.offset;

            // Handle nested designators (e.g., .a.j = 2): drill into sub-struct
            let has_nested_designator = item.designators.len() > 1
                && matches!(item.designators.first(), Some(Designator::Field(_)));
            if has_nested_designator {
                if let Some(sub_layout) = self.get_struct_layout_for_ctype(&field_layout.ty) {
                    let sub_item = InitializerItem {
                        designators: item.designators[1..].to_vec(),
                        init: item.init.clone(),
                    };
                    self.write_struct_init_to_bytes(bytes, field_offset, &[sub_item], &sub_layout);
                }
                current_field_idx = field_idx + 1;
                continue;
            }

            match &item.init {
                Initializer::Expr(expr) => {
                    if let Expr::StringLiteral(s, _) = expr {
                        // String literal initializing a char array field
                        if let CType::Array(_, Some(arr_size)) = &field_layout.ty {
                            let s_bytes = s.as_bytes();
                            for (i, &b) in s_bytes.iter().enumerate() {
                                if i >= *arr_size { break; }
                                if field_offset + i < bytes.len() {
                                    bytes[field_offset + i] = b;
                                }
                            }
                            if s_bytes.len() < *arr_size && field_offset + s_bytes.len() < bytes.len() {
                                bytes[field_offset + s_bytes.len()] = 0;
                            }
                        }
                    } else {
                        let val = self.eval_const_expr(expr).unwrap_or(IrConst::I64(0));
                        let field_ir_ty = IrType::from_ctype(&field_layout.ty);
                        if let (Some(bit_offset), Some(bit_width)) = (field_layout.bit_offset, field_layout.bit_width) {
                            self.write_bitfield_to_bytes(bytes, field_offset, &val, field_ir_ty, bit_offset, bit_width);
                        } else {
                            self.write_const_to_bytes(bytes, field_offset, &val, field_ir_ty);
                        }
                    }
                }
                Initializer::List(sub_items) => {
                    // Nested struct/union: recurse if the field is a struct type
                    if let Some(sub_layout) = self.get_struct_layout_for_ctype(&field_layout.ty) {
                        self.write_struct_init_to_bytes(bytes, field_offset, sub_items, &sub_layout);
                    } else {
                        // Array field or other nested init: try to write elements sequentially
                        if let CType::Array(ref elem_ty, _) = field_layout.ty {
                            let elem_ir_ty = IrType::from_ctype(elem_ty);
                            let elem_size = elem_ty.size();
                            for (i, sub_item) in sub_items.iter().enumerate() {
                                if let Initializer::Expr(expr) = &sub_item.init {
                                    let val = self.eval_const_expr(expr).unwrap_or(IrConst::I64(0));
                                    self.write_const_to_bytes(bytes, field_offset + i * elem_size, &val, elem_ir_ty);
                                }
                            }
                        } else if let Some(first) = sub_items.first() {
                            if let Initializer::Expr(expr) = &first.init {
                                let val = self.eval_const_expr(expr).unwrap_or(IrConst::I64(0));
                                let field_ir_ty = IrType::from_ctype(&field_layout.ty);
                                self.write_const_to_bytes(bytes, field_offset, &val, field_ir_ty);
                            }
                        }
                    }
                }
            }

            current_field_idx = field_idx + 1;

            // For unions with flat init, only the first member can be initialized.
            // Designated inits can overwrite (last designator wins).
            if layout.is_union && designator_name.is_none() {
                break;
            }
        }
    }

    /// Resolve a pointer field's initializer expression to a GlobalInit.
    /// Handles string literals, global addresses, function pointers, etc.
    fn resolve_ptr_field_init(&mut self, expr: &Expr) -> Option<GlobalInit> {
        // String literal: create a .rodata entry and reference it
        if let Expr::StringLiteral(s, _) = expr {
            let label = format!(".Lstr{}", self.next_string);
            self.next_string += 1;
            self.module.string_literals.push((label.clone(), s.clone()));
            return Some(GlobalInit::GlobalAddr(label));
        }
        // Try as a global address expression (&x, func name, array name, etc.)
        if let Some(addr) = self.eval_global_addr_expr(expr) {
            return Some(addr);
        }
        // Integer constant 0 -> null pointer
        if let Some(val) = self.eval_const_expr(expr) {
            if let Some(v) = self.const_to_i64(&val) {
                if v == 0 {
                    return None; // Will be zero in the byte buffer
                }
            }
            // Non-zero constant pointer (unusual but possible)
            return Some(GlobalInit::Scalar(val));
        }
        None
    }

    /// Get a StructLayout for a CType if it's a struct or union.
    fn get_struct_layout_for_ctype(&self, ty: &CType) -> Option<StructLayout> {
        match ty {
            CType::Struct(st) => {
                // First try to look up by name in registered struct_layouts
                if let Some(ref name) = st.name {
                    let key = format!("struct.{}", name);
                    if let Some(layout) = self.struct_layouts.get(&key) {
                        return Some(layout.clone());
                    }
                }
                // Compute from fields
                Some(StructLayout::for_struct(&st.fields))
            }
            CType::Union(st) => {
                if let Some(ref name) = st.name {
                    let key = format!("union.{}", name);
                    if let Some(layout) = self.struct_layouts.get(&key) {
                        return Some(layout.clone());
                    }
                }
                Some(StructLayout::for_union(&st.fields))
            }
            _ => None,
        }
    }

    /// Lower an array of structs where some fields are pointers.
    /// Uses byte-level serialization but with Compound for address elements.
    /// Each struct element is emitted as a mix of byte constants and pointer-sized addresses.
    fn lower_struct_array_with_ptrs(
        &mut self,
        items: &[InitializerItem],
        layout: &StructLayout,
        num_elems: usize,
    ) -> GlobalInit {
        // We emit the entire array as a sequence of Compound elements.
        // Each element is either:
        //   - Scalar(I8) for byte-level constant data
        //   - GlobalAddr for pointer fields
        let struct_size = layout.size;
        let total_size = num_elems * struct_size;
        let mut compound_elements: Vec<GlobalInit> = Vec::new();

        // Initialize with zero bytes
        let mut bytes = vec![0u8; total_size];
        // Track which byte ranges are pointer fields that need address relocations
        let mut ptr_ranges: Vec<(usize, GlobalInit)> = Vec::new(); // (byte_offset, addr_init)

        for elem_idx in 0..num_elems {
            let item = items.get(elem_idx);
            let base_offset = elem_idx * struct_size;

            if let Some(item) = item {
                match &item.init {
                    Initializer::List(sub_items) => {
                        let mut current_field_idx = 0usize;
                        for sub_item in sub_items {
                            let desig_name = match sub_item.designators.first() {
                                Some(Designator::Field(ref name)) => Some(name.as_str()),
                                _ => None,
                            };
                            let field_idx = match layout.resolve_init_field_idx(desig_name, current_field_idx) {
                                Some(idx) => idx,
                                None => break,
                            };
                            let field = &layout.fields[field_idx];
                            let field_offset = base_offset + field.offset;
                            let field_ir_ty = IrType::from_ctype(&field.ty);
                            let is_ptr_field = matches!(field.ty, CType::Pointer(_));

                            if let Initializer::Expr(expr) = &sub_item.init {
                                if is_ptr_field {
                                    if let Some(addr_init) = self.resolve_ptr_field_init(expr) {
                                        ptr_ranges.push((field_offset, addr_init));
                                    } else if let Some(val) = self.eval_const_expr(expr) {
                                        self.write_const_to_bytes(&mut bytes, field_offset, &val, field_ir_ty);
                                    }
                                } else {
                                    if let Some(val) = self.eval_const_expr(expr) {
                                        self.write_const_to_bytes(&mut bytes, field_offset, &val, field_ir_ty);
                                    }
                                }
                            }
                            current_field_idx = field_idx + 1;
                        }
                    }
                    Initializer::Expr(expr) => {
                        // Single expression for first field
                        if !layout.fields.is_empty() {
                            let field = &layout.fields[0];
                            let field_offset = base_offset + field.offset;
                            let field_ir_ty = IrType::from_ctype(&field.ty);
                            let is_ptr_field = matches!(field.ty, CType::Pointer(_));
                            if is_ptr_field {
                                if let Some(addr_init) = self.resolve_ptr_field_init(expr) {
                                    ptr_ranges.push((field_offset, addr_init));
                                }
                            } else if let Some(val) = self.eval_const_expr(expr) {
                                self.write_const_to_bytes(&mut bytes, field_offset, &val, field_ir_ty);
                            }
                        }
                    }
                }
            }
        }

        // Sort ptr_ranges by offset
        ptr_ranges.sort_by_key(|&(off, _)| off);

        // Emit the byte stream, replacing pointer-sized regions with GlobalAddr elements
        let mut pos = 0;
        for (ptr_off, ref addr_init) in &ptr_ranges {
            // Emit bytes before this pointer
            while pos < *ptr_off {
                compound_elements.push(GlobalInit::Scalar(IrConst::I8(bytes[pos] as i8)));
                pos += 1;
            }
            // Emit the pointer reference
            compound_elements.push(addr_init.clone());
            pos += 8; // pointer is 8 bytes
        }
        // Emit remaining bytes
        while pos < total_size {
            compound_elements.push(GlobalInit::Scalar(IrConst::I8(bytes[pos] as i8)));
            pos += 1;
        }

        GlobalInit::Compound(compound_elements)
    }

    /// Collect all enum constants from the entire translation unit.
    fn collect_all_enum_constants(&mut self, tu: &TranslationUnit) {
        for decl in &tu.decls {
            match decl {
                ExternalDecl::Declaration(d) => {
                    self.collect_enum_constants(&d.type_spec);
                }
                ExternalDecl::FunctionDef(func) => {
                    self.collect_enum_constants(&func.return_type);
                    self.collect_enum_constants_from_compound(&func.body);
                }
            }
        }
    }

    /// Collect enum constants from a type specifier.
    pub(super) fn collect_enum_constants(&mut self, ts: &TypeSpecifier) {
        match ts {
            TypeSpecifier::Enum(_, Some(variants)) => {
                let mut next_val: i64 = 0;
                for variant in variants {
                    if let Some(ref expr) = variant.value {
                        if let Some(val) = self.eval_const_expr(expr) {
                            if let Some(v) = self.const_to_i64(&val) {
                                next_val = v;
                            }
                        }
                    }
                    self.enum_constants.insert(variant.name.clone(), next_val);
                    next_val += 1;
                }
            }
            // Recurse into struct/union fields to find enum definitions within them
            TypeSpecifier::Struct(_, Some(fields), _) | TypeSpecifier::Union(_, Some(fields), _) => {
                for field in fields {
                    self.collect_enum_constants(&field.type_spec);
                }
            }
            // Unwrap Array and Pointer wrappers to find nested enum definitions.
            // This handles cases like: enum { A, B } volatile arr[2][2]; inside structs,
            // where the field type becomes Array(Array(Enum(...))).
            TypeSpecifier::Array(inner, _) | TypeSpecifier::Pointer(inner) => {
                self.collect_enum_constants(inner);
            }
            _ => {}
        }
    }

    /// Recursively collect enum constants from a compound statement.
    fn collect_enum_constants_from_compound(&mut self, compound: &CompoundStmt) {
        for item in &compound.items {
            match item {
                BlockItem::Declaration(decl) => {
                    self.collect_enum_constants(&decl.type_spec);
                }
                BlockItem::Statement(stmt) => {
                    self.collect_enum_constants_from_stmt(stmt);
                }
            }
        }
    }

    /// Recursively collect enum constants from a statement.
    fn collect_enum_constants_from_stmt(&mut self, stmt: &Stmt) {
        match stmt {
            Stmt::Compound(compound) => self.collect_enum_constants_from_compound(compound),
            Stmt::If(_, then_stmt, else_stmt, _) => {
                self.collect_enum_constants_from_stmt(then_stmt);
                if let Some(else_s) = else_stmt {
                    self.collect_enum_constants_from_stmt(else_s);
                }
            }
            Stmt::While(_, body, _) | Stmt::DoWhile(body, _, _) => {
                self.collect_enum_constants_from_stmt(body);
            }
            Stmt::For(_, _, _, body, _) => {
                self.collect_enum_constants_from_stmt(body);
            }
            Stmt::Switch(_, body, _) => {
                self.collect_enum_constants_from_stmt(body);
            }
            Stmt::Case(_, stmt, _) | Stmt::Default(stmt, _) | Stmt::Label(_, stmt, _) => {
                self.collect_enum_constants_from_stmt(stmt);
            }
            _ => {}
        }
    }


    /// For a pointer-to-struct parameter type (e.g., `struct TAG *p`), get the
    /// pointed-to struct's layout. This enables `p->field` access.
    pub(super) fn get_struct_layout_for_pointer_param(&self, type_spec: &TypeSpecifier) -> Option<StructLayout> {
        // Resolve typedefs first (e.g., typedef union Outer *OuterPtr)
        let resolved = self.resolve_type_spec(type_spec);
        match resolved {
            TypeSpecifier::Pointer(inner) => self.get_struct_layout_for_type(inner),
            _ => None,
        }
    }

    /// Compute the IR type of the pointee for a pointer/array type specifier.
    /// For `Pointer(Char)`, returns Some(I8).
    /// For `Pointer(Int)`, returns Some(I32).
    /// For `Array(Int, _)`, returns Some(I32).
    /// Resolves typedef names before pattern matching.
    pub(super) fn pointee_ir_type(&self, type_spec: &TypeSpecifier) -> Option<IrType> {
        let resolved = self.resolve_type_spec(type_spec);
        match &resolved {
            TypeSpecifier::Pointer(inner) => Some(self.type_spec_to_ir(inner)),
            TypeSpecifier::Array(inner, _) => Some(self.type_spec_to_ir(inner)),
            _ => None,
        }
    }

    /// Compute the pointee type for a declaration, considering both the base type
    /// specifier and derived declarators (pointer/array).
    /// For `char *s` (type_spec=Char, derived=[Pointer]): returns Some(I8)
    /// For `int *p` (type_spec=Int, derived=[Pointer]): returns Some(I32)
    /// For `int **pp` (type_spec=Int, derived=[Pointer, Pointer]): returns Some(Ptr)
    /// For `int a[10]` (type_spec=Int, derived=[Array(10)]): returns Some(I32)
    pub(super) fn compute_pointee_type(&self, type_spec: &TypeSpecifier, derived: &[DerivedDeclarator]) -> Option<IrType> {
        // Count pointer and array levels
        let ptr_count = derived.iter().filter(|d| matches!(d, DerivedDeclarator::Pointer)).count();
        let has_array = derived.iter().any(|d| matches!(d, DerivedDeclarator::Array(_)));

        if ptr_count > 1 {
            // Multi-level pointer (e.g., int **pp) - pointee is a pointer
            Some(IrType::Ptr)
        } else if ptr_count == 1 {
            // Single pointer - pointee is the base type
            if has_array {
                Some(IrType::Ptr)
            } else {
                match type_spec {
                    TypeSpecifier::Pointer(inner) => Some(self.type_spec_to_ir(inner)),
                    _ => Some(self.type_spec_to_ir(type_spec)),
                }
            }
        } else if has_array {
            // Array (e.g., int a[10]) - element type is the base type
            Some(self.type_spec_to_ir(type_spec))
        } else {
            // Check if the type_spec itself is a pointer
            self.pointee_ir_type(type_spec)
        }
    }

    /// Check if an lvalue expression targets a _Bool variable (requires normalization).
    /// Handles direct identifiers, pointer dereferences (*pval), array subscripts (arr[i]),
    /// and member accesses (s.field, p->field) where the target type is _Bool.
    pub(super) fn is_bool_lvalue(&self, expr: &Expr) -> bool {
        match expr {
            Expr::Identifier(name, _) => {
                if let Some(info) = self.locals.get(name) {
                    return info.is_bool;
                }
                // Check global variables for _Bool type
                if let Some(ginfo) = self.globals.get(name) {
                    if let Some(ref ct) = ginfo.c_type {
                        return matches!(ct, CType::Bool);
                    }
                }
                false
            }
            Expr::Deref(_, _)
            | Expr::ArraySubscript(_, _, _)
            | Expr::MemberAccess(_, _, _)
            | Expr::PointerMemberAccess(_, _, _) => {
                // Use CType resolution to check if the lvalue target is _Bool
                if let Some(ct) = self.get_expr_ctype(expr) {
                    return matches!(ct, CType::Bool);
                }
                false
            }
            _ => false,
        }
    }

    /// Check if an expression has pointer type (for pointer arithmetic).
    pub(super) fn expr_is_pointer(&self, expr: &Expr) -> bool {
        match expr {
            Expr::Identifier(name, _) => {
                if let Some(info) = self.locals.get(name) {
                    // Arrays decay to pointers in expression context
                    return (info.ty == IrType::Ptr || info.is_array) && !info.is_struct;
                }
                if let Some(ginfo) = self.globals.get(name) {
                    return (ginfo.ty == IrType::Ptr || ginfo.is_array) && !ginfo.is_struct;
                }
                false
            }
            Expr::AddressOf(_, _) => true,
            Expr::PostfixOp(_, inner, _) => self.expr_is_pointer(inner),
            Expr::UnaryOp(op, inner, _) => {
                match op {
                    UnaryOp::PreInc | UnaryOp::PreDec => self.expr_is_pointer(inner),
                    _ => false,
                }
            }
            Expr::ArraySubscript(base, _, _) => {
                // Result of subscript on pointer-to-pointer
                if let Some(pt) = self.get_pointee_type_of_expr(base) {
                    return pt == IrType::Ptr;
                }
                false
            }
            Expr::Cast(ref type_spec, _, _) => {
                matches!(type_spec, TypeSpecifier::Pointer(_))
            }
            Expr::StringLiteral(_, _) => true,
            Expr::BinaryOp(op, lhs, rhs, _) => {
                match op {
                    BinOp::Add => {
                        // ptr + int or int + ptr yields a pointer
                        self.expr_is_pointer(lhs) || self.expr_is_pointer(rhs)
                    }
                    BinOp::Sub => {
                        // ptr - int yields a pointer; ptr - ptr yields an integer
                        let lhs_ptr = self.expr_is_pointer(lhs);
                        let rhs_ptr = self.expr_is_pointer(rhs);
                        lhs_ptr && !rhs_ptr
                    }
                    _ => false,
                }
            }
            Expr::Conditional(_, then_expr, else_expr, _) => {
                self.expr_is_pointer(then_expr) || self.expr_is_pointer(else_expr)
            }
            Expr::Comma(_, rhs, _) => self.expr_is_pointer(rhs),
            Expr::FunctionCall(func, _, _) => {
                // Check CType for function call return
                if let Some(ctype) = self.get_expr_ctype(expr) {
                    return matches!(ctype, CType::Pointer(_));
                }
                // Fallback: check IrType return type
                if let Expr::Identifier(name, _) = func.as_ref() {
                    if let Some(&ret_ty) = self.func_meta.return_types.get(name.as_str()) {
                        return ret_ty == IrType::Ptr;
                    }
                }
                false
            }
            Expr::MemberAccess(base_expr, field_name, _) => {
                // Struct member that is an array (decays to pointer) or pointer type
                if let Some(ctype) = self.resolve_member_field_ctype(base_expr, field_name) {
                    return matches!(ctype, CType::Array(_, _) | CType::Pointer(_));
                }
                false
            }
            Expr::PointerMemberAccess(base_expr, field_name, _) => {
                // Pointer member access: p->field where field is array or pointer
                if let Some(ctype) = self.resolve_pointer_member_field_ctype(base_expr, field_name) {
                    return matches!(ctype, CType::Array(_, _) | CType::Pointer(_));
                }
                false
            }
            Expr::Deref(_, _) => {
                // Dereferencing a pointer-to-array yields an array which decays to pointer.
                // Dereferencing a pointer-to-pointer yields a pointer.
                if let Some(ctype) = self.get_expr_ctype(expr) {
                    return matches!(ctype, CType::Array(_, _) | CType::Pointer(_));
                }
                false
            }
            Expr::Assign(_, _, _) | Expr::CompoundAssign(_, _, _, _) => {
                // Assignment result has the type of the LHS
                if let Some(ctype) = self.get_expr_ctype(expr) {
                    return matches!(ctype, CType::Array(_, _) | CType::Pointer(_));
                }
                false
            }
            _ => false,
        }
    }

    /// Get the element size for a pointer expression (for scaling in pointer arithmetic).
    /// For `int *p`, returns 4. For `char *s`, returns 1.
    pub(super) fn get_pointer_elem_size_from_expr(&self, expr: &Expr) -> usize {
        // Try CType-based resolution first for accurate type information
        if let Some(ctype) = self.get_expr_ctype(expr) {
            match &ctype {
                CType::Pointer(pointee) => return pointee.size().max(1),
                CType::Array(elem, _) => return elem.size().max(1),
                _ => {}
            }
        }
        match expr {
            Expr::Identifier(name, _) => {
                // Check locals then globals for pointee_type or elem_size.
                if let Some(info) = self.locals.get(name) {
                    if let Some(pt) = info.pointee_type {
                        return pt.size();
                    }
                    if info.elem_size > 0 {
                        return info.elem_size;
                    }
                }
                if let Some(ginfo) = self.globals.get(name) {
                    if let Some(pt) = ginfo.pointee_type {
                        return pt.size();
                    }
                    if ginfo.elem_size > 0 {
                        return ginfo.elem_size;
                    }
                }
                8
            }
            Expr::PostfixOp(_, inner, _) => self.get_pointer_elem_size_from_expr(inner),
            Expr::UnaryOp(op, inner, _) => {
                match op {
                    UnaryOp::PreInc | UnaryOp::PreDec => self.get_pointer_elem_size_from_expr(inner),
                    _ => 8,
                }
            }
            Expr::BinaryOp(op, lhs, rhs, _) => {
                // ptr + int or ptr - int: get elem size from the pointer operand
                match op {
                    BinOp::Add => {
                        if self.expr_is_pointer(lhs) {
                            self.get_pointer_elem_size_from_expr(lhs)
                        } else if self.expr_is_pointer(rhs) {
                            self.get_pointer_elem_size_from_expr(rhs)
                        } else {
                            8
                        }
                    }
                    BinOp::Sub => {
                        if self.expr_is_pointer(lhs) {
                            self.get_pointer_elem_size_from_expr(lhs)
                        } else {
                            8
                        }
                    }
                    _ => 8,
                }
            }
            Expr::Conditional(_, then_expr, _, _) => self.get_pointer_elem_size_from_expr(then_expr),
            Expr::Comma(_, rhs, _) => self.get_pointer_elem_size_from_expr(rhs),
            Expr::FunctionCall(_, _, _) => {
                if let Some(ctype) = self.get_expr_ctype(expr) {
                    if let CType::Pointer(pointee) = &ctype {
                        return pointee.size().max(1);
                    }
                }
                8
            }
            Expr::AddressOf(inner, _) => {
                // &x: pointer to typeof(x)
                let ty = self.get_expr_type(inner);
                ty.size()
            }
            Expr::Cast(ref type_spec, _, _) => {
                if let TypeSpecifier::Pointer(ref inner) = type_spec {
                    self.sizeof_type(inner)
                } else {
                    8
                }
            }
            Expr::MemberAccess(base_expr, field_name, _) => {
                if let Some(ctype) = self.resolve_member_field_ctype(base_expr, field_name) {
                    match &ctype {
                        CType::Array(elem_ty, _) => return elem_ty.size(),
                        CType::Pointer(pointee_ty) => return pointee_ty.size(),
                        _ => {}
                    }
                }
                8
            }
            Expr::PointerMemberAccess(base_expr, field_name, _) => {
                if let Some(ctype) = self.resolve_pointer_member_field_ctype(base_expr, field_name) {
                    match &ctype {
                        CType::Array(elem_ty, _) => return elem_ty.size(),
                        CType::Pointer(pointee_ty) => return pointee_ty.size(),
                        _ => {}
                    }
                }
                8
            }
            _ => {
                // Try using get_pointee_type_of_expr as a fallback
                if let Some(pt) = self.get_pointee_type_of_expr(expr) {
                    return pt.size();
                }
                8
            }
        }
    }

    /// Get the pointee type for a pointer expression - i.e., what type you get when dereferencing it.
    pub(super) fn get_pointee_type_of_expr(&self, expr: &Expr) -> Option<IrType> {
        // First try CType-based resolution (handles multi-level pointers correctly)
        if let Some(ctype) = self.get_expr_ctype(expr) {
            match ctype {
                CType::Pointer(inner) => return Some(IrType::from_ctype(&inner)),
                CType::Array(elem, _) => return Some(IrType::from_ctype(&elem)),
                _ => {}
            }
        }
        match expr {
            Expr::Identifier(name, _) => {
                if let Some(info) = self.locals.get(name) {
                    return info.pointee_type;
                }
                if let Some(ginfo) = self.globals.get(name) {
                    return ginfo.pointee_type;
                }
                None
            }
            Expr::PostfixOp(_, inner, _) => {
                self.get_pointee_type_of_expr(inner)
            }
            Expr::UnaryOp(op, inner, _) => {
                match op {
                    UnaryOp::PreInc | UnaryOp::PreDec => {
                        self.get_pointee_type_of_expr(inner)
                    }
                    _ => None,
                }
            }
            Expr::BinaryOp(_, lhs, rhs, _) => {
                if let Some(pt) = self.get_pointee_type_of_expr(lhs) {
                    return Some(pt);
                }
                self.get_pointee_type_of_expr(rhs)
            }
            Expr::Cast(ref type_spec, inner, _) => {
                if let TypeSpecifier::Pointer(ref pointee_ts) = type_spec {
                    let pt = self.type_spec_to_ir(pointee_ts);
                    return Some(pt);
                }
                self.get_pointee_type_of_expr(inner)
            }
            Expr::Conditional(_, then_expr, else_expr, _) => {
                if let Some(pt) = self.get_pointee_type_of_expr(then_expr) {
                    return Some(pt);
                }
                self.get_pointee_type_of_expr(else_expr)
            }
            Expr::Comma(_, last, _) => {
                self.get_pointee_type_of_expr(last)
            }
            Expr::AddressOf(inner, _) => {
                let ty = self.get_expr_type(inner);
                Some(ty)
            }
            Expr::Assign(_, rhs, _) => {
                self.get_pointee_type_of_expr(rhs)
            }
            _ => None,
        }
    }

    /// Get or create a unique IR label for a user-defined goto label.
    pub(super) fn get_or_create_user_label(&mut self, name: &str) -> String {
        let key = format!("{}::{}", self.current_function_name, name);
        if let Some(label) = self.user_labels.get(&key) {
            label.clone()
        } else {
            let label = self.fresh_label(&format!("user_{}", name));
            self.user_labels.insert(key, label.clone());
            label
        }
    }

    /// Flatten a multi-dimensional array initializer list for global arrays.
    /// Handles C initialization rules:
    /// - Braced sub-lists map to the next sub-array dimension, padded with zeros
    /// - Bare scalar expressions fill base elements left-to-right without sub-array padding
    fn flatten_global_array_init(
        &self,
        items: &[InitializerItem],
        array_dim_strides: &[usize],
        base_ty: IrType,
        values: &mut Vec<IrConst>,
    ) {
        let base_type_size = base_ty.size().max(1);
        if array_dim_strides.len() <= 1 {
            for item in items {
                self.flatten_global_init_item(&item.init, base_ty, values);
            }
            return;
        }
        // Number of base elements per sub-array at this dimension level
        let sub_elem_count = if array_dim_strides[0] > 0 && base_type_size > 0 {
            array_dim_strides[0] / base_type_size
        } else {
            1
        };
        for item in items {
            match &item.init {
                Initializer::List(sub_items) => {
                    // Braced sub-list: recurse into next dimension, then pad to sub_elem_count
                    let start_len = values.len();
                    self.flatten_global_array_init(sub_items, &array_dim_strides[1..], base_ty, values);
                    while values.len() < start_len + sub_elem_count {
                        values.push(self.zero_const(base_ty));
                    }
                }
                Initializer::Expr(expr) => {
                    if let Expr::StringLiteral(s, _) = expr {
                        // String literal initializing a char sub-array: inline the bytes
                        let start_len = values.len();
                        for &byte in s.as_bytes() {
                            values.push(IrConst::I64(byte as i64));
                        }
                        // Add null terminator if room
                        if values.len() < start_len + sub_elem_count {
                            values.push(IrConst::I64(0));
                        }
                        // Pad to sub_elem_count
                        while values.len() < start_len + sub_elem_count {
                            values.push(self.zero_const(base_ty));
                        }
                        // Truncate if string was too long for the sub-array
                        if values.len() > start_len + sub_elem_count {
                            values.truncate(start_len + sub_elem_count);
                        }
                    } else if let Some(val) = self.eval_const_expr(expr) {
                        // Bare scalar: fills one base element, no sub-array padding
                        let expr_ty = self.get_expr_type(expr);
                        values.push(self.coerce_const_to_type_with_src(val, base_ty, expr_ty));
                    } else {
                        values.push(self.zero_const(base_ty));
                    }
                }
            }
        }
    }

    /// Check if an initializer item contains an address expression or string literal,
    /// recursing into nested Initializer::List items (for double-brace init like {{"str"}}).
    fn init_contains_addr_expr(item: &InitializerItem, is_multidim_char_array: bool) -> bool {
        match &item.init {
            Initializer::Expr(expr) => {
                if matches!(expr, Expr::StringLiteral(_, _)) {
                    !is_multidim_char_array
                } else {
                    // Cannot call self methods in a static context, so conservatively
                    // return false for non-string expressions; the caller handles
                    // address expressions via eval_global_addr_expr separately.
                    false
                }
            }
            Initializer::List(sub_items) => {
                sub_items.iter().any(|sub| Self::init_contains_addr_expr(sub, is_multidim_char_array))
            }
        }
    }

    /// Check if an initializer item contains a string literal anywhere (including nested lists).
    fn init_contains_string_literal(item: &InitializerItem) -> bool {
        match &item.init {
            Initializer::Expr(expr) => matches!(expr, Expr::StringLiteral(_, _)),
            Initializer::List(sub_items) => {
                sub_items.iter().any(|sub| Self::init_contains_string_literal(sub))
            }
        }
    }

    /// Collect a single compound initializer element, handling nested lists (double-brace init).
    /// For `{{"str"}}`, unwraps the nested list to find the string literal.
    /// For `{"str"}`, directly handles the string literal expression.
    fn collect_compound_init_element(&mut self, init: &Initializer, elements: &mut Vec<GlobalInit>) {
        match init {
            Initializer::Expr(expr) => {
                if let Expr::StringLiteral(s, _) = expr {
                    // String literal: create .rodata entry and use its label
                    let label = format!(".Lstr{}", self.next_string);
                    self.next_string += 1;
                    self.module.string_literals.push((label.clone(), s.clone()));
                    elements.push(GlobalInit::GlobalAddr(label));
                } else if let Expr::LabelAddr(label_name, _) = expr {
                    // GCC &&label extension: emit label address as GlobalAddr
                    let scoped_label = self.get_or_create_user_label(label_name);
                    elements.push(GlobalInit::GlobalAddr(scoped_label));
                } else if let Some(val) = self.eval_const_expr(expr) {
                    elements.push(GlobalInit::Scalar(val));
                } else if let Some(addr) = self.eval_global_addr_expr(expr) {
                    elements.push(addr);
                } else {
                    elements.push(GlobalInit::Zero);
                }
            }
            Initializer::List(sub_items) => {
                // Double-brace init like {{"str"}} or {{expr}}:
                // Unwrap the nested list and process the first element as the value
                // for this array slot.
                if sub_items.len() >= 1 {
                    self.collect_compound_init_element(&sub_items[0].init, elements);
                } else {
                    elements.push(GlobalInit::Zero);
                }
            }
        }
    }

    /// Flatten a single initializer item, recursing into nested lists.
    fn flatten_global_init_item(&self, init: &Initializer, base_ty: IrType, values: &mut Vec<IrConst>) {
        match init {
            Initializer::Expr(expr) => {
                if let Some(val) = self.eval_const_expr(expr) {
                    let expr_ty = self.get_expr_type(expr);
                    values.push(self.coerce_const_to_type_with_src(val, base_ty, expr_ty));
                } else {
                    values.push(self.zero_const(base_ty));
                }
            }
            Initializer::List(items) => {
                for item in items {
                    self.flatten_global_init_item(&item.init, base_ty, values);
                }
            }
        }
    }

    /// Copy a string literal's bytes into an alloca at a given byte offset,
    /// followed by a null terminator. Used for `char s[] = "hello"` and
    /// string elements in array initializer lists.
    pub(super) fn emit_string_to_alloca(&mut self, alloca: Value, s: &str, base_offset: usize) {
        let bytes = s.as_bytes();
        for (j, &byte) in bytes.iter().enumerate() {
            let val = Operand::Const(IrConst::I8(byte as i8));
            let offset = Operand::Const(IrConst::I64((base_offset + j) as i64));
            let addr = self.fresh_value();
            self.emit(Instruction::GetElementPtr {
                dest: addr, base: alloca, offset, ty: IrType::I8,
            });
            self.emit(Instruction::Store { val, ptr: addr, ty: IrType::I8 });
        }
        // Null terminator
        let null_offset = Operand::Const(IrConst::I64((base_offset + bytes.len()) as i64));
        let null_addr = self.fresh_value();
        self.emit(Instruction::GetElementPtr {
            dest: null_addr, base: alloca, offset: null_offset, ty: IrType::I8,
        });
        self.emit(Instruction::Store {
            val: Operand::Const(IrConst::I8(0)), ptr: null_addr, ty: IrType::I8,
        });
    }

    /// Emit a single element store at a given byte offset in an alloca.
    /// Handles implicit type cast from the expression type to the target type.
    pub(super) fn emit_array_element_store(
        &mut self, alloca: Value, val: Operand, offset: usize, ty: IrType,
    ) {
        let offset_val = Operand::Const(IrConst::I64(offset as i64));
        let elem_addr = self.fresh_value();
        self.emit(Instruction::GetElementPtr {
            dest: elem_addr, base: alloca, offset: offset_val, ty,
        });
        self.emit(Instruction::Store { val, ptr: elem_addr, ty });
    }

    /// Zero-initialize an alloca by emitting stores of zero.
    pub(super) fn zero_init_alloca(&mut self, alloca: Value, total_size: usize) {
        let mut offset = 0usize;
        while offset + 8 <= total_size {
            let addr = self.fresh_value();
            self.emit(Instruction::GetElementPtr {
                dest: addr,
                base: alloca,
                offset: Operand::Const(IrConst::I64(offset as i64)),
                ty: IrType::I64,
            });
            self.emit(Instruction::Store {
                val: Operand::Const(IrConst::I64(0)),
                ptr: addr,
                ty: IrType::I64,
            });
            offset += 8;
        }
        while offset < total_size {
            let addr = self.fresh_value();
            self.emit(Instruction::GetElementPtr {
                dest: addr,
                base: alloca,
                offset: Operand::Const(IrConst::I64(offset as i64)),
                ty: IrType::I8,
            });
            self.emit(Instruction::Store {
                val: Operand::Const(IrConst::I8(0)),
                ptr: addr,
                ty: IrType::I8,
            });
            offset += 1;
        }
    }
}

impl Default for Lowerer {
    fn default() -> Self {
        Self::new()
    }
}
