//! Byte-serialization portion of global initialization.
//!
//! This module contains the byte-level serialization methods used during global
//! variable initialization lowering. It handles writing constants, bitfields,
//! complex numbers, struct layouts, and array fills into byte buffers.

use crate::frontend::parser::ast::*;
use crate::ir::ir::*;
use crate::common::types::{IrType, StructLayout, CType};
use super::lowering::Lowerer;

/// Append `count` zero bytes (as `GlobalInit::Scalar(IrConst::I8(0))`) to `elements`.
/// Used throughout global initialization to emit padding and zero-fill.
pub(super) fn push_zero_bytes(elements: &mut Vec<GlobalInit>, count: usize) {
    for _ in 0..count {
        elements.push(GlobalInit::Scalar(IrConst::I8(0)));
    }
}

/// Result of filling an array/FAM field in fill_struct_global_bytes,
/// indicating how to advance the item index.
pub(super) struct ArrayFillResult {
    new_item_idx: usize,
    /// If true, caller should `continue` (skip the default field_idx update).
    skip_update: bool,
}

impl Lowerer {
    /// Recursively fill byte buffer for struct global initialization.
    /// Returns the number of initializer items consumed.
    ///
    /// Handles nested structs/unions, arrays (including multi-dimensional), string
    /// literals, designators, flexible array members, and bitfields.
    pub(super) fn fill_struct_global_bytes(
        &self,
        items: &[InitializerItem],
        layout: &StructLayout,
        bytes: &mut [u8],
        base_offset: usize,
    ) -> usize {
        let mut item_idx = 0usize;
        let mut current_field_idx = 0usize;

        while item_idx < items.len() {
            let item = &items[item_idx];

            let designator_name = match item.designators.first() {
                Some(Designator::Field(ref name)) => Some(name.as_str()),
                _ => None,
            };
            let array_start_idx = self.extract_index_designator(item, designator_name.is_some());
            let field_idx = match layout.resolve_init_field_idx(designator_name, current_field_idx) {
                Some(idx) => idx,
                None => {
                    if designator_name.is_some() { item_idx += 1; continue; }
                    break;
                }
            };
            let field_layout = &layout.fields[field_idx];
            let field_offset = base_offset + field_layout.offset;

            let has_nested_designator = item.designators.len() > 1
                && matches!(item.designators.first(), Some(Designator::Field(_)));

            match &field_layout.ty {
                // Nested designator into struct/union: drill into sub-composite
                CType::Struct(st) if has_nested_designator => {
                    self.fill_nested_designator_composite(
                        item, &StructLayout::for_struct(&st.fields), bytes, field_offset,
                    );
                    item_idx += 1;
                }
                CType::Union(st) if has_nested_designator => {
                    self.fill_nested_designator_composite(
                        item, &StructLayout::for_union(&st.fields), bytes, field_offset,
                    );
                    item_idx += 1;
                }
                // Nested designator into array: .field[idx] = val
                // After the designated element, continue consuming non-designated
                // items for subsequent array positions (C11 6.7.9p17).
                CType::Array(elem_ty, Some(arr_size)) if has_nested_designator => {
                    let arr_size = *arr_size;
                    let desig_idx = self.fill_nested_designator_array(item, elem_ty, arr_size, bytes, field_offset);
                    item_idx += 1;
                    // Continue consuming subsequent non-designated items for positions
                    // desig_idx+1, desig_idx+2, ... within the same array field
                    let elem_size = elem_ty.size();
                    let elem_ir_ty = IrType::from_ctype(elem_ty);
                    let mut ai = desig_idx + 1;
                    while ai < arr_size && item_idx < items.len() {
                        let next_item = &items[item_idx];
                        if !next_item.designators.is_empty() {
                            break;
                        }
                        if let Initializer::Expr(ref expr) = next_item.init {
                            let val = self.eval_const_expr(expr).unwrap_or(IrConst::I64(0));
                            let elem_offset = field_offset + ai * elem_size;
                            self.write_const_to_bytes(bytes, elem_offset, &val, elem_ir_ty);
                        } else {
                            break;
                        }
                        item_idx += 1;
                        ai += 1;
                    }
                }
                // Struct or union field (non-nested designator)
                CType::Struct(st) => {
                    let sub_layout = StructLayout::for_struct(&st.fields);
                    item_idx += self.fill_composite_field(
                        &items[item_idx..], &sub_layout, bytes, field_offset,
                    );
                }
                CType::Union(st) => {
                    let sub_layout = StructLayout::for_union(&st.fields);
                    item_idx += self.fill_composite_field(
                        &items[item_idx..], &sub_layout, bytes, field_offset,
                    );
                }
                // Fixed-size array field
                CType::Array(elem_ty, Some(arr_size)) => {
                    let advanced = self.fill_array_field(
                        items, item_idx, elem_ty, *arr_size,
                        bytes, field_offset, array_start_idx,
                    );
                    if advanced.skip_update {
                        item_idx = advanced.new_item_idx;
                        current_field_idx = field_idx + 1;
                        continue;
                    }
                    item_idx = advanced.new_item_idx;
                }
                // Flexible array member (FAM)
                CType::Array(elem_ty, None) => {
                    let advanced = self.fill_fam_field(
                        items, item_idx, elem_ty, bytes, field_offset,
                    );
                    if advanced.skip_update {
                        item_idx = advanced.new_item_idx;
                        current_field_idx = field_idx + 1;
                        continue;
                    }
                    item_idx = advanced.new_item_idx;
                }
                // Complex field: write {real, imag} pair to bytes
                CType::ComplexFloat | CType::ComplexDouble | CType::ComplexLongDouble => {
                    self.write_complex_field_to_bytes(bytes, field_offset, &field_layout.ty, &item.init);
                    item_idx += 1;
                }
                // Scalar field (possibly bitfield)
                _ => {
                    let field_ir_ty = IrType::from_ctype(&field_layout.ty);
                    let val = self.eval_init_scalar(&item.init);
                    if let (Some(bit_offset), Some(bit_width)) = (field_layout.bit_offset, field_layout.bit_width) {
                        self.write_bitfield_to_bytes(bytes, field_offset, &val, field_ir_ty, bit_offset, bit_width);
                    } else {
                        self.write_const_to_bytes(bytes, field_offset, &val, field_ir_ty);
                    }
                    item_idx += 1;
                }
            }
            current_field_idx = field_idx + 1;

            if layout.is_union && designator_name.is_none() {
                break;
            }
        }
        item_idx
    }

    // --- fill_struct_global_bytes helpers ---

    /// Extract an array index designator from an initializer item.
    pub(super) fn extract_index_designator(&self, item: &InitializerItem, has_field_desig: bool) -> Option<usize> {
        if has_field_desig {
            item.designators.iter().find_map(|d| {
                if let Designator::Index(ref idx_expr) = d {
                    self.eval_const_expr(idx_expr).and_then(|c| c.to_usize())
                } else {
                    None
                }
            })
        } else {
            match item.designators.first() {
                Some(Designator::Index(ref idx_expr)) => {
                    self.eval_const_expr(idx_expr).and_then(|c| c.to_usize())
                }
                _ => None,
            }
        }
    }

    /// Evaluate an initializer to a scalar constant (handles both Expr and brace-wrapped List).
    pub(super) fn eval_init_scalar(&self, init: &Initializer) -> IrConst {
        match init {
            Initializer::Expr(expr) => self.eval_const_expr(expr).unwrap_or(IrConst::I64(0)),
            Initializer::List(sub_items) => {
                sub_items.first()
                    .and_then(|first| {
                        if let Initializer::Expr(expr) = &first.init {
                            self.eval_const_expr(expr)
                        } else {
                            None
                        }
                    })
                    .unwrap_or(IrConst::I64(0))
            }
        }
    }

    /// Write a string literal into a byte buffer at the given offset, with null terminator.
    /// Each char in the string is treated as a raw byte value (0-255).
    pub(super) fn write_string_to_bytes(bytes: &mut [u8], offset: usize, s: &str, max_len: usize) {
        let str_chars: Vec<u8> = s.chars().map(|c| c as u8).collect();
        for (i, &b) in str_chars.iter().enumerate() {
            if i >= max_len { break; }
            if offset + i < bytes.len() {
                bytes[offset + i] = b;
            }
        }
        if str_chars.len() < max_len && offset + str_chars.len() < bytes.len() {
            bytes[offset + str_chars.len()] = 0;
        }
    }

    /// Handle nested designator drilling into a struct/union sub-field (e.g., .a.b = val).
    pub(super) fn fill_nested_designator_composite(
        &self, item: &InitializerItem, sub_layout: &StructLayout,
        bytes: &mut [u8], field_offset: usize,
    ) {
        let sub_item = InitializerItem {
            designators: item.designators[1..].to_vec(),
            init: item.init.clone(),
        };
        self.fill_struct_global_bytes(&[sub_item], sub_layout, bytes, field_offset);
    }

    /// Process a nested designator into an array field (e.g., .field[idx] = val).
    /// Returns the array index that was designated.
    pub(super) fn fill_nested_designator_array(
        &self, item: &InitializerItem, elem_ty: &CType, arr_size: usize,
        bytes: &mut [u8], field_offset: usize,
    ) -> usize {
        let elem_size = elem_ty.size();
        let elem_ir_ty = IrType::from_ctype(elem_ty);

        // Collect all Index and Field designators after the first (which is Field("name"))
        // For .a[1][2].b we have designators: [Field("a"), Index(1), Index(2), Field("b")]
        // After stripping Field("a"), remaining: [Index(1), Index(2), Field("b")]
        let remaining = &item.designators[1..];

        // Find first Index designator (outer array index)
        let (first_idx_pos, idx) = remaining.iter().enumerate().find_map(|(i, d)| {
            if let Designator::Index(ref idx_expr) = d {
                self.eval_const_expr(idx_expr).and_then(|c| c.to_usize()).map(|v| (i, v))
            } else {
                None
            }
        }).unwrap_or((0, 0));

        if idx >= arr_size {
            return idx;
        }

        let elem_offset = field_offset + idx * elem_size;

        // Check for further designators after the first Index
        let after_first_idx = &remaining[first_idx_pos + 1..];

        // Collect remaining Field designators for struct drilling
        let remaining_field_desigs: Vec<_> = after_first_idx.iter()
            .filter(|d| matches!(d, Designator::Field(_)))
            .cloned()
            .collect();

        // Collect remaining Index designators for multi-dimensional array drilling
        let remaining_index_desigs: Vec<_> = after_first_idx.iter()
            .filter(|d| matches!(d, Designator::Index(_)))
            .cloned()
            .collect();

        if !remaining_field_desigs.is_empty() {
            // Drill into struct element: .a[1].b = val
            if !remaining_index_desigs.is_empty() {
                // .a[1].b[2] - remaining has both field and index
                // Build designator list with fields and indices from after_first_idx
                let sub_desigs: Vec<_> = after_first_idx.iter().cloned().collect();
                if let Some(sub_layout) = self.get_struct_layout_for_ctype(elem_ty) {
                    let sub_item = InitializerItem {
                        designators: sub_desigs,
                        init: item.init.clone(),
                    };
                    self.fill_struct_global_bytes(&[sub_item], &sub_layout, bytes, elem_offset);
                }
            } else {
                if let Some(sub_layout) = self.get_struct_layout_for_ctype(elem_ty) {
                    let sub_item = InitializerItem {
                        designators: remaining_field_desigs,
                        init: item.init.clone(),
                    };
                    self.fill_struct_global_bytes(&[sub_item], &sub_layout, bytes, elem_offset);
                }
            }
        } else if !remaining_index_desigs.is_empty() {
            // Multi-dimensional array: .a[1][2] = val
            // elem_ty is the inner array type (e.g., float[10] for float a[3][10])
            if let CType::Array(inner_elem_ty, Some(inner_size)) = elem_ty {
                // Recursively handle the inner array with the remaining index designators
                let inner_idx = remaining_index_desigs.iter().find_map(|d| {
                    if let Designator::Index(ref idx_expr) = d {
                        self.eval_const_expr(idx_expr).and_then(|c| c.to_usize())
                    } else {
                        None
                    }
                }).unwrap_or(0);
                if inner_idx < *inner_size {
                    let inner_elem_size = inner_elem_ty.size();
                    let inner_ir_ty = IrType::from_ctype(inner_elem_ty);
                    let inner_offset = elem_offset + inner_idx * inner_elem_size;

                    // Check for even more Index designators (3D+ arrays)
                    let further_indices: Vec<_> = remaining_index_desigs[1..].to_vec();
                    if !further_indices.is_empty() {
                        if let CType::Array(deeper_elem, Some(deeper_size)) = inner_elem_ty.as_ref() {
                            // Build sub-item with remaining indices as [Field("dummy"), Index(...)]
                            // Actually we can recursively call ourselves
                            let sub_item = InitializerItem {
                                designators: {
                                    let mut d = vec![Designator::Field(String::new())]; // dummy field
                                    d.extend(further_indices);
                                    d
                                },
                                init: item.init.clone(),
                            };
                            self.fill_nested_designator_array(
                                &sub_item, inner_elem_ty, *inner_size,
                                bytes, elem_offset,
                            );
                        }
                    } else if let Initializer::Expr(ref expr) = item.init {
                        if let Expr::StringLiteral(s, _) = expr {
                            if let CType::Array(deep_inner, Some(deep_size)) = inner_elem_ty.as_ref() {
                                if matches!(deep_inner.as_ref(), CType::Char | CType::UChar) {
                                    Self::write_string_to_bytes(bytes, inner_offset, s, *deep_size);
                                } else {
                                    let val = self.eval_const_expr(expr).unwrap_or(IrConst::I64(0));
                                    self.write_const_to_bytes(bytes, inner_offset, &val, inner_ir_ty);
                                }
                            } else {
                                let val = self.eval_const_expr(expr).unwrap_or(IrConst::I64(0));
                                self.write_const_to_bytes(bytes, inner_offset, &val, inner_ir_ty);
                            }
                        } else {
                            let val = self.eval_const_expr(expr).unwrap_or(IrConst::I64(0));
                            self.write_const_to_bytes(bytes, inner_offset, &val, inner_ir_ty);
                        }
                    }
                }
            }
        } else if let Initializer::Expr(ref expr) = item.init {
            // No further designators - store value at elem_offset
            // Handle string literal initializing a char array element
            // (e.g., .a[1] = "abc" where a is char a[3][10])
            if let Expr::StringLiteral(s, _) = expr {
                if let CType::Array(inner, Some(inner_size)) = elem_ty {
                    if matches!(inner.as_ref(), CType::Char | CType::UChar) {
                        Self::write_string_to_bytes(bytes, elem_offset, s, *inner_size);
                    } else {
                        let val = self.eval_const_expr(expr).unwrap_or(IrConst::I64(0));
                        self.write_const_to_bytes(bytes, elem_offset, &val, elem_ir_ty);
                    }
                } else if matches!(elem_ty, CType::Char | CType::UChar) {
                    let val = s.chars().next().map(|c| IrConst::I8(c as u8 as i8)).unwrap_or(IrConst::I8(0));
                    self.write_const_to_bytes(bytes, elem_offset, &val, elem_ir_ty);
                } else {
                    let val = self.eval_const_expr(expr).unwrap_or(IrConst::I64(0));
                    self.write_const_to_bytes(bytes, elem_offset, &val, elem_ir_ty);
                }
            } else {
                let val = self.eval_const_expr(expr).unwrap_or(IrConst::I64(0));
                self.write_const_to_bytes(bytes, elem_offset, &val, elem_ir_ty);
            }
        } else if let Initializer::List(ref sub_items) = item.init {
            // Handle list init for array element (e.g., .a[1] = {1,2,3})
            match elem_ty {
                CType::Array(inner_elem_ty, Some(inner_size)) => {
                    let inner_elem_size = inner_elem_ty.size();
                    let inner_ir_ty = IrType::from_ctype(inner_elem_ty);
                    for (si, sub_item) in sub_items.iter().enumerate() {
                        if si >= *inner_size { break; }
                        if let Initializer::Expr(ref expr) = sub_item.init {
                            let val = self.eval_const_expr(expr).unwrap_or(IrConst::I64(0));
                            let inner_offset = elem_offset + si * inner_elem_size;
                            self.write_const_to_bytes(bytes, inner_offset, &val, inner_ir_ty);
                        }
                    }
                }
                CType::Struct(ref st) => {
                    let sub_layout = StructLayout::for_struct(&st.fields);
                    self.fill_struct_global_bytes(sub_items, &sub_layout, bytes, elem_offset);
                }
                _ => {}
            }
        }
        idx
    }

    /// Fill a composite (struct/union) field from an initializer.
    /// Returns the number of items consumed.
    pub(super) fn fill_composite_field(
        &self, items: &[InitializerItem], sub_layout: &StructLayout,
        bytes: &mut [u8], field_offset: usize,
    ) -> usize {
        match &items[0].init {
            Initializer::List(sub_items) => {
                self.fill_struct_global_bytes(sub_items, sub_layout, bytes, field_offset);
                1
            }
            Initializer::Expr(_) => {
                let consumed = self.fill_struct_global_bytes(items, sub_layout, bytes, field_offset);
                if consumed == 0 { 1 } else { consumed }
            }
        }
    }

    /// Fill a fixed-size array field. Handles string literals, arrays of composites,
    /// multi-dimensional arrays, arrays of scalars with designators, and flat initialization.
    pub(super) fn fill_array_field(
        &self,
        items: &[InitializerItem],
        item_idx: usize,
        elem_ty: &CType,
        arr_size: usize,
        bytes: &mut [u8],
        field_offset: usize,
        array_start_idx: Option<usize>,
    ) -> ArrayFillResult {
        let item = &items[item_idx];
        let elem_size = elem_ty.size();
        let elem_ir_ty = IrType::from_ctype(elem_ty);

        match &item.init {
            Initializer::List(sub_items) => {
                // Check for brace-wrapped string literal: { "hello" }
                if self.try_fill_string_literal_init(sub_items, elem_ty, arr_size, bytes, field_offset) {
                    return ArrayFillResult { new_item_idx: item_idx + 1, skip_update: true };
                }
                if matches!(elem_ty, CType::Struct(_) | CType::Union(_)) {
                    self.fill_array_of_composites(sub_items, elem_ty, arr_size, elem_size, bytes, field_offset);
                } else if let CType::Array(inner_elem, Some(inner_size)) = elem_ty {
                    // Multi-dimensional array field (e.g., int a[2][3] or struct S a[2][2][2]).
                    // Each sub-item is a brace group for one element of the outer dimension.
                    self.fill_multidim_array_field(
                        sub_items, inner_elem, *inner_size, arr_size, elem_size,
                        bytes, field_offset,
                    );
                } else {
                    self.fill_array_of_scalars(sub_items, arr_size, elem_size, elem_ir_ty, bytes, field_offset);
                }
                ArrayFillResult { new_item_idx: item_idx + 1, skip_update: false }
            }
            Initializer::Expr(expr) => {
                // String literal for char array
                if let Expr::StringLiteral(s, _) = expr {
                    if matches!(elem_ty, CType::Char | CType::UChar) {
                        Self::write_string_to_bytes(bytes, field_offset, s, arr_size);
                        return ArrayFillResult { new_item_idx: item_idx + 1, skip_update: true };
                    }
                }
                // Flat init from consecutive items.
                // For multi-dimensional arrays (elem_ty is Array), use leaf element
                // info so that flat scalars fill the entire array correctly.
                let start_ai = array_start_idx.unwrap_or(0);
                let leaf_composite = Self::leaf_composite_type(elem_ty);
                let new_idx = if matches!(elem_ty, CType::Struct(_) | CType::Union(_)) {
                    self.fill_flat_array_of_composites(
                        items, item_idx, elem_ty, arr_size, elem_size, elem_ir_ty,
                        bytes, field_offset, start_ai,
                    )
                } else if let Some(composite_ty) = leaf_composite {
                    // Multi-dimensional array of structs/unions: flat init fills composites
                    let composite_size = composite_ty.size();
                    let composite_ir_ty = IrType::from_ctype(composite_ty);
                    let total_composites = if composite_size > 0 { (arr_size * elem_size) / composite_size } else { 0 };
                    self.fill_flat_array_of_composites(
                        items, item_idx, composite_ty, total_composites, composite_size, composite_ir_ty,
                        bytes, field_offset, start_ai,
                    )
                } else if matches!(elem_ty, CType::Array(_, _)) {
                    // Multi-dimensional array of scalars: use leaf element size
                    let leaf_size = Self::leaf_elem_size(elem_ty);
                    let leaf_ir_ty = Self::leaf_ir_type(elem_ty);
                    let total_scalars = if leaf_size > 0 { (arr_size * elem_size) / leaf_size } else { 0 };
                    self.fill_flat_array_of_scalars(
                        items, item_idx, total_scalars, leaf_size, leaf_ir_ty,
                        bytes, field_offset, start_ai,
                    )
                } else {
                    self.fill_flat_array_of_scalars(
                        items, item_idx, arr_size, elem_size, elem_ir_ty,
                        bytes, field_offset, start_ai,
                    )
                };
                ArrayFillResult { new_item_idx: new_idx, skip_update: true }
            }
        }
    }

    /// Fill a multi-dimensional array field from a braced initializer list.
    /// Handles arrays like `int a[2][3]`, `struct S a[2][2][2]`, `union U a[3][4]`, etc.
    /// Each sub-item at this level represents one element of the outermost dimension.
    fn fill_multidim_array_field(
        &self,
        sub_items: &[InitializerItem],
        inner_elem_ty: &CType,
        inner_arr_size: usize,
        outer_arr_size: usize,
        outer_elem_size: usize,
        bytes: &mut [u8],
        field_offset: usize,
    ) {
        let inner_elem_size = inner_elem_ty.size();
        let mut sub_idx = 0usize;
        let mut ai = 0usize;
        while ai < outer_arr_size && sub_idx < sub_items.len() {
            let elem_offset = field_offset + ai * outer_elem_size;
            match &sub_items[sub_idx].init {
                Initializer::List(inner_items) => {
                    // Brace group for this outer element: recurse into inner array
                    self.fill_array_field_recursive(
                        inner_items, inner_elem_ty, inner_arr_size,
                        bytes, elem_offset,
                    );
                    sub_idx += 1;
                }
                Initializer::Expr(_) => {
                    // Flat init: fill inner array elements from consecutive Expr items.
                    // Determine the leaf type to figure out how to consume items.
                    let leaf_composite = Self::leaf_composite_type(inner_elem_ty);
                    if let Some(composite_ty) = leaf_composite {
                        // The leaf elements are structs/unions: fill them field by field
                        let composite_layout = self.get_composite_layout(composite_ty);
                        let composite_size = composite_ty.size();
                        let composites_per_outer = if composite_size > 0 { outer_elem_size / composite_size } else { 0 };
                        let mut ci = 0usize;
                        while sub_idx < sub_items.len() && ci < composites_per_outer {
                            let comp_offset = elem_offset + ci * composite_size;
                            let consumed = self.fill_struct_global_bytes(
                                &sub_items[sub_idx..], &composite_layout, bytes, comp_offset,
                            );
                            sub_idx += consumed.max(1);
                            ci += 1;
                        }
                    } else {
                        // Leaf elements are scalars
                        let leaf_size = Self::leaf_elem_size(inner_elem_ty);
                        let scalars_per_outer = if leaf_size > 0 { outer_elem_size / leaf_size } else { 1 };
                        let leaf_ir_ty = Self::leaf_ir_type(inner_elem_ty);
                        let mut filled = 0usize;
                        while sub_idx < sub_items.len() && filled < scalars_per_outer {
                            if let Initializer::Expr(e) = &sub_items[sub_idx].init {
                                let val = self.eval_const_expr(e).unwrap_or(IrConst::I64(0));
                                self.write_const_to_bytes(bytes, elem_offset + filled * leaf_size, &val, leaf_ir_ty);
                                sub_idx += 1;
                                filled += 1;
                            } else {
                                break;
                            }
                        }
                    }
                }
            }
            ai += 1;
        }
    }

    /// Recursively fill a (possibly multi-dimensional) array from a braced initializer list.
    /// Called by fill_multidim_array_field to handle inner dimensions.
    fn fill_array_field_recursive(
        &self,
        items: &[InitializerItem],
        elem_ty: &CType,
        arr_size: usize,
        bytes: &mut [u8],
        field_offset: usize,
    ) {
        let elem_size = elem_ty.size();

        if let CType::Array(inner_elem, Some(inner_size)) = elem_ty {
            // Still multi-dimensional: recurse
            self.fill_multidim_array_field(
                items, inner_elem, *inner_size, arr_size, elem_size,
                bytes, field_offset,
            );
        } else if matches!(elem_ty, CType::Struct(_) | CType::Union(_)) {
            self.fill_array_of_composites(items, elem_ty, arr_size, elem_size, bytes, field_offset);
        } else {
            let elem_ir_ty = IrType::from_ctype(elem_ty);
            self.fill_array_of_scalars(items, arr_size, elem_size, elem_ir_ty, bytes, field_offset);
        }
    }

    /// Get the leaf (innermost non-array) element size for a possibly nested array type.
    fn leaf_elem_size(ty: &CType) -> usize {
        match ty {
            CType::Array(inner, _) => Self::leaf_elem_size(inner),
            _ => ty.size(),
        }
    }

    /// Get the leaf (innermost non-array) IR type for a possibly nested array type.
    fn leaf_ir_type(ty: &CType) -> IrType {
        match ty {
            CType::Array(inner, _) => Self::leaf_ir_type(inner),
            _ => IrType::from_ctype(ty),
        }
    }

    /// Get the leaf (innermost non-array) composite type, if the leaf is a struct/union.
    /// Returns None if the leaf is a scalar type.
    fn leaf_composite_type(ty: &CType) -> Option<&CType> {
        match ty {
            CType::Array(inner, _) => Self::leaf_composite_type(inner),
            CType::Struct(_) | CType::Union(_) => Some(ty),
            _ => None,
        }
    }

    /// Fill a flexible array member (FAM) field.
    pub(super) fn fill_fam_field(
        &self,
        items: &[InitializerItem],
        item_idx: usize,
        elem_ty: &CType,
        bytes: &mut [u8],
        field_offset: usize,
    ) -> ArrayFillResult {
        let elem_size = elem_ty.size();
        let elem_ir_ty = IrType::from_ctype(elem_ty);

        match &items[item_idx].init {
            Initializer::List(sub_items) => {
                for (ai, sub_item) in sub_items.iter().enumerate() {
                    let elem_offset = field_offset + ai * elem_size;
                    if elem_offset + elem_size > bytes.len() { break; }
                    let val = self.eval_init_scalar(&sub_item.init);
                    self.write_const_to_bytes(bytes, elem_offset, &val, elem_ir_ty);
                }
                ArrayFillResult { new_item_idx: item_idx + 1, skip_update: false }
            }
            Initializer::Expr(expr) => {
                // String literal initializing a char FAM: write bytes directly
                if let Expr::StringLiteral(s, _) = expr {
                    if matches!(elem_ty, CType::Char | CType::UChar) {
                        let max_len = bytes.len().saturating_sub(field_offset);
                        Self::write_string_to_bytes(bytes, field_offset, s, max_len);
                        return ArrayFillResult { new_item_idx: item_idx + 1, skip_update: true };
                    }
                }
                let mut ai = 0usize;
                let val = self.eval_const_expr(expr).unwrap_or(IrConst::I64(0));
                let elem_offset = field_offset + ai * elem_size;
                if elem_offset + elem_size <= bytes.len() {
                    self.write_const_to_bytes(bytes, elem_offset, &val, elem_ir_ty);
                }
                ai += 1;
                let mut new_idx = item_idx + 1;
                while new_idx < items.len() {
                    let next_item = &items[new_idx];
                    if !next_item.designators.is_empty() { break; }
                    if let Initializer::Expr(e) = &next_item.init {
                        let val = self.eval_const_expr(e).unwrap_or(IrConst::I64(0));
                        let elem_offset = field_offset + ai * elem_size;
                        if elem_offset + elem_size <= bytes.len() {
                            self.write_const_to_bytes(bytes, elem_offset, &val, elem_ir_ty);
                        }
                        ai += 1;
                        new_idx += 1;
                    } else {
                        break;
                    }
                }
                ArrayFillResult { new_item_idx: new_idx, skip_update: true }
            }
        }
    }

    /// Try to interpret a brace-wrapped init list as a string literal for a char array.
    /// Returns true if handled.
    pub(super) fn try_fill_string_literal_init(
        &self, sub_items: &[InitializerItem], elem_ty: &CType, arr_size: usize,
        bytes: &mut [u8], field_offset: usize,
    ) -> bool {
        if sub_items.len() == 1 && sub_items[0].designators.is_empty() {
            if let Initializer::Expr(Expr::StringLiteral(s, _)) = &sub_items[0].init {
                if matches!(elem_ty, CType::Char | CType::UChar) {
                    Self::write_string_to_bytes(bytes, field_offset, s, arr_size);
                    return true;
                }
            }
        }
        false
    }

    /// Fill an array of struct/union elements from a braced sub-item list.
    pub(super) fn fill_array_of_composites(
        &self, sub_items: &[InitializerItem], elem_ty: &CType,
        arr_size: usize, elem_size: usize, bytes: &mut [u8], field_offset: usize,
    ) {
        let sub_layout = self.get_composite_layout(elem_ty);
        let mut sub_idx = 0usize;
        let mut ai = 0usize;
        while ai < arr_size && sub_idx < sub_items.len() {
            let elem_offset = field_offset + ai * elem_size;
            match &sub_items[sub_idx].init {
                Initializer::List(inner_items) => {
                    self.fill_struct_global_bytes(inner_items, &sub_layout, bytes, elem_offset);
                    sub_idx += 1;
                }
                Initializer::Expr(_) => {
                    let consumed = self.fill_struct_global_bytes(&sub_items[sub_idx..], &sub_layout, bytes, elem_offset);
                    sub_idx += consumed;
                }
            }
            ai += 1;
        }
    }

    /// Fill an array of scalar elements from a braced sub-item list (with designator support).
    pub(super) fn fill_array_of_scalars(
        &self, sub_items: &[InitializerItem], arr_size: usize,
        elem_size: usize, elem_ir_ty: IrType, bytes: &mut [u8], field_offset: usize,
    ) {
        let mut ai = 0usize;
        for sub_item in sub_items.iter() {
            if let Some(Designator::Index(ref idx_expr)) = sub_item.designators.first() {
                if let Some(idx) = self.eval_const_expr(idx_expr).and_then(|c| c.to_usize()) {
                    ai = idx;
                }
            }
            if ai >= arr_size { break; }
            let elem_offset = field_offset + ai * elem_size;
            let val = self.eval_init_scalar(&sub_item.init);
            self.write_const_to_bytes(bytes, elem_offset, &val, elem_ir_ty);
            ai += 1;
        }
    }

    /// Fill flat init of an array of composites from consecutive items.
    /// Returns the new item_idx.
    pub(super) fn fill_flat_array_of_composites(
        &self, items: &[InitializerItem], mut item_idx: usize,
        elem_ty: &CType, arr_size: usize, elem_size: usize, elem_ir_ty: IrType,
        bytes: &mut [u8], field_offset: usize, start_ai: usize,
    ) -> usize {
        let sub_layout = self.get_composite_layout(elem_ty);
        if matches!(elem_ty, CType::Struct(_)) {
            for ai in start_ai..arr_size {
                if item_idx >= items.len() { break; }
                let elem_offset = field_offset + ai * elem_size;
                let consumed = self.fill_struct_global_bytes(&items[item_idx..], &sub_layout, bytes, elem_offset);
                item_idx += consumed;
            }
        } else {
            // Union: take one item per element
            for ai in start_ai..arr_size {
                if item_idx >= items.len() { break; }
                let elem_offset = field_offset + ai * elem_size;
                if let Initializer::Expr(e) = &items[item_idx].init {
                    let val = self.eval_const_expr(e).unwrap_or(IrConst::I64(0));
                    self.write_const_to_bytes(bytes, elem_offset, &val, elem_ir_ty);
                }
                item_idx += 1;
            }
        }
        item_idx
    }

    /// Fill flat init of an array of scalars from consecutive items.
    /// Returns the new item_idx.
    pub(super) fn fill_flat_array_of_scalars(
        &self, items: &[InitializerItem], item_idx: usize,
        arr_size: usize, elem_size: usize, elem_ir_ty: IrType,
        bytes: &mut [u8], field_offset: usize, start_ai: usize,
    ) -> usize {
        let mut consumed = 0usize;
        let mut ai = start_ai;
        while ai < arr_size && (item_idx + consumed) < items.len() {
            let cur_item = &items[item_idx + consumed];
            if !cur_item.designators.is_empty() && consumed > 0 { break; }
            if let Initializer::Expr(e) = &cur_item.init {
                let val = self.eval_const_expr(e).unwrap_or(IrConst::I64(0));
                let elem_offset = field_offset + ai * elem_size;
                self.write_const_to_bytes(bytes, elem_offset, &val, elem_ir_ty);
                consumed += 1;
                ai += 1;
            } else {
                break;
            }
        }
        item_idx + consumed.max(1)
    }

    /// Fill a multi-dimensional array of structs/unions into a byte buffer.
    ///
    /// Recursively processes brace-enclosed initializer lists to handle arrays with
    /// 3+ dimensions correctly. Each brace nesting level corresponds to one array
    /// dimension, and `array_dim_strides` tells us how many bytes each level spans.
    ///
    /// For `struct S arr[2][2][2]` with struct_size=8, strides=[32, 16, 8]:
    /// - Top-level items fill stride[0]=32 bytes each (a [2][2] sub-array = 4 structs)
    /// - Second-level brace groups fill stride[1]=16 bytes each (a [2] sub-array = 2 structs)
    /// - Innermost brace groups fill stride[2]=8 bytes each (1 struct)
    pub(super) fn fill_multidim_struct_array_bytes(
        &self,
        items: &[InitializerItem],
        layout: &StructLayout,
        struct_size: usize,
        array_dim_strides: &[usize],
        bytes: &mut [u8],
        base_offset: usize,
        region_size: usize,
    ) {
        if struct_size == 0 { return; }

        // Determine the stride for elements at this brace level.
        // If we have strides info, use it; otherwise treat each item as one struct.
        let (this_stride, remaining_strides) = if array_dim_strides.len() > 1 {
            (array_dim_strides[0], &array_dim_strides[1..])
        } else if array_dim_strides.len() == 1 {
            (array_dim_strides[0], &array_dim_strides[0..0])
        } else {
            (struct_size, &array_dim_strides[0..0])
        };

        let num_elems = if this_stride > 0 { region_size / this_stride } else { 0 };
        let mut current_idx = 0usize;
        let mut item_idx = 0usize;

        while item_idx < items.len() {
            let item = &items[item_idx];

            // Check for index designator (may jump backwards for out-of-order designated inits)
            let has_index_designator = if let Some(Designator::Index(ref idx_expr)) = item.designators.first() {
                if let Some(idx) = self.eval_const_expr(idx_expr).and_then(|c| c.to_usize()) {
                    current_idx = idx;
                }
                true
            } else {
                false
            };
            if current_idx >= num_elems {
                // Only skip items without a designator that would reset the index;
                // designated items explicitly set current_idx above
                if !has_index_designator { break; }
                item_idx += 1;
                continue;
            }

            // Check for field designator: [idx].field = val
            let field_designator_name = item.designators.iter().find_map(|d| {
                if let Designator::Field(ref name) = d {
                    Some(name.clone())
                } else {
                    None
                }
            });

            let elem_offset = base_offset + current_idx * this_stride;

            match &item.init {
                Initializer::List(sub_items) => {
                    if this_stride > struct_size && !remaining_strides.is_empty() {
                        // This brace group represents a sub-array (not a single struct).
                        // Recurse with the next dimension's strides.
                        self.fill_multidim_struct_array_bytes(
                            sub_items, layout, struct_size, remaining_strides,
                            bytes, elem_offset, this_stride,
                        );
                    } else {
                        // This brace group represents a single struct initializer.
                        self.write_struct_init_to_bytes(bytes, elem_offset, sub_items, layout);
                    }
                    item_idx += 1;
                }
                Initializer::Expr(expr) => {
                    if let Some(ref fname) = field_designator_name {
                        // [idx].field = val: write to specific field
                        if let Some(val) = self.eval_const_expr(expr) {
                            if let Some(field) = layout.fields.iter().find(|f| &f.name == fname) {
                                let field_ir_ty = IrType::from_ctype(&field.ty);
                                self.write_const_to_bytes(bytes, elem_offset + field.offset, &val, field_ir_ty);
                            }
                        }
                        item_idx += 1;
                    } else {
                        // Flat init: consume items for struct fields sequentially.
                        // Fill structs one by one across the entire region.
                        let max_structs = if struct_size > 0 { region_size / struct_size } else { 0 };
                        let flat_struct_base = (elem_offset - base_offset) / struct_size;
                        let mut fi = flat_struct_base;
                        while item_idx < items.len() && fi < max_structs {
                            let byte_off = base_offset + fi * struct_size;
                            if byte_off + struct_size > bytes.len() { break; }
                            let consumed = self.fill_struct_global_bytes(&items[item_idx..], layout, bytes, byte_off);
                            item_idx += consumed.max(1);
                            fi += 1;
                        }
                        // Skip the normal current_idx increment since we consumed everything
                        continue;
                    }
                }
            }
            // Only advance current_idx if no field designator (sequential init)
            if field_designator_name.is_none() {
                current_idx += 1;
            }
        }
    }

    /// Get the StructLayout for a composite (struct or union) CType.
    pub(super) fn get_composite_layout(&self, ty: &CType) -> StructLayout {
        match ty {
            CType::Struct(st) => StructLayout::for_struct(&st.fields),
            CType::Union(st) => StructLayout::for_union(&st.fields),
            _ => unreachable!("get_composite_layout called on non-composite type"),
        }
    }

    /// Push a constant value as individual bytes into a compound init element list.
    pub(super) fn push_const_as_bytes(&self, elements: &mut Vec<GlobalInit>, val: &IrConst, size: usize) {
        let mut bytes = Vec::with_capacity(size);
        val.push_le_bytes(&mut bytes, size);
        for b in bytes {
            elements.push(GlobalInit::Scalar(IrConst::I8(b as i8)));
        }
    }

    /// Write an IrConst value to a byte buffer at the given offset using the field's IR type.
    pub(super) fn write_const_to_bytes(&self, bytes: &mut [u8], offset: usize, val: &IrConst, ty: IrType) {
        let coerced = val.coerce_to(ty);
        let size = ty.size();
        let mut le_buf = Vec::with_capacity(size);
        coerced.push_le_bytes(&mut le_buf, size);
        for (i, &b) in le_buf.iter().enumerate() {
            if offset + i < bytes.len() {
                bytes[offset + i] = b;
            }
        }
    }

    /// Write a bitfield value into a byte buffer at the given offset.
    /// Uses read-modify-write to pack the value at the correct bit position.
    pub(super) fn write_bitfield_to_bytes(&self, bytes: &mut [u8], offset: usize, val: &IrConst, ty: IrType, bit_offset: u32, bit_width: u32) {
        let int_val = val.to_u64().unwrap_or(0);

        let size = ty.size();
        let mask = if bit_width >= 64 { u64::MAX } else { (1u64 << bit_width) - 1 };
        let field_val = (int_val & mask) << bit_offset;
        let clear_mask = !(mask << bit_offset);

        // Read current storage unit value (little-endian)
        let mut current = 0u64;
        for i in 0..size {
            if offset + i < bytes.len() {
                current |= (bytes[offset + i] as u64) << (i * 8);
            }
        }

        // Modify: clear field bits and OR in new value
        let new_val = (current & clear_mask) | field_val;

        // Write back (little-endian)
        let le = new_val.to_le_bytes();
        for i in 0..size {
            if offset + i < bytes.len() {
                bytes[offset + i] = le[i];
            }
        }
    }

    /// Write a complex field ({real, imag} pair) to a byte buffer.
    /// Evaluates the initializer as a complex constant expression and writes
    /// both components at the correct offsets within the field.
    pub(super) fn write_complex_field_to_bytes(
        &self,
        bytes: &mut [u8],
        field_offset: usize,
        complex_ctype: &CType,
        init: &Initializer,
    ) {
        let comp_size = match complex_ctype {
            CType::ComplexFloat => 4,
            CType::ComplexDouble => 8,
            CType::ComplexLongDouble => 16,
            _ => 8,
        };

        // Try to extract (real, imag) from the initializer
        let (real, imag) = match init {
            Initializer::Expr(expr) => {
                self.eval_complex_const_public(expr).unwrap_or((0.0, 0.0))
            }
            Initializer::List(items) => {
                // {real, imag} or {real} (imag defaults to 0)
                let real_val = items.first().and_then(|item| {
                    if let Initializer::Expr(e) = &item.init {
                        self.eval_const_expr(e).and_then(|c| match c {
                            IrConst::F64(v) => Some(v),
                            IrConst::F32(v) => Some(v as f64),
                            IrConst::I64(v) => Some(v as f64),
                            IrConst::I32(v) => Some(v as f64),
                            IrConst::LongDouble(v) => Some(v),
                            _ => None,
                        })
                    } else {
                        None
                    }
                }).unwrap_or(0.0);
                let imag_val = items.get(1).and_then(|item| {
                    if let Initializer::Expr(e) = &item.init {
                        self.eval_const_expr(e).and_then(|c| match c {
                            IrConst::F64(v) => Some(v),
                            IrConst::F32(v) => Some(v as f64),
                            IrConst::I64(v) => Some(v as f64),
                            IrConst::I32(v) => Some(v as f64),
                            IrConst::LongDouble(v) => Some(v),
                            _ => None,
                        })
                    } else {
                        None
                    }
                }).unwrap_or(0.0);
                (real_val, imag_val)
            }
        };

        // Write real part at field_offset
        match complex_ctype {
            CType::ComplexFloat => {
                let real_const = IrConst::F32(real as f32);
                let imag_const = IrConst::F32(imag as f32);
                self.write_const_to_bytes(bytes, field_offset, &real_const, IrType::F32);
                self.write_const_to_bytes(bytes, field_offset + comp_size, &imag_const, IrType::F32);
            }
            CType::ComplexLongDouble => {
                let real_const = IrConst::LongDouble(real);
                let imag_const = IrConst::LongDouble(imag);
                self.write_const_to_bytes(bytes, field_offset, &real_const, IrType::F128);
                self.write_const_to_bytes(bytes, field_offset + comp_size, &imag_const, IrType::F128);
            }
            _ => {
                // ComplexDouble
                let real_const = IrConst::F64(real);
                let imag_const = IrConst::F64(imag);
                self.write_const_to_bytes(bytes, field_offset, &real_const, IrType::F64);
                self.write_const_to_bytes(bytes, field_offset + comp_size, &imag_const, IrType::F64);
            }
        }
    }

    /// Write a struct initializer list to a byte buffer at the given base offset.
    /// Handles nested struct fields recursively.
    pub(super) fn write_struct_init_to_bytes(
        &self,
        bytes: &mut [u8],
        base_offset: usize,
        items: &[InitializerItem],
        layout: &StructLayout,
    ) {
        let mut current_field_idx = 0usize;
        for item in items {
            let designator_name = match item.designators.first() {
                Some(Designator::Field(ref name)) => Some(name.as_str()),
                _ => None,
            };
            let field_idx = match layout.resolve_init_field_idx(designator_name, current_field_idx) {
                Some(idx) => idx,
                None => break,
            };

            let field_layout = &layout.fields[field_idx];
            let field_offset = base_offset + field_layout.offset;

            // Handle nested designators (e.g., .a.j = 2): drill into sub-struct
            let has_nested_designator = item.designators.len() > 1
                && matches!(item.designators.first(), Some(Designator::Field(_)));
            if has_nested_designator {
                if let Some(sub_layout) = self.get_struct_layout_for_ctype(&field_layout.ty) {
                    let sub_item = InitializerItem {
                        designators: item.designators[1..].to_vec(),
                        init: item.init.clone(),
                    };
                    self.write_struct_init_to_bytes(bytes, field_offset, &[sub_item], &sub_layout);
                }
                current_field_idx = field_idx + 1;
                continue;
            }

            // Complex fields: use specialized handler for {real, imag} pair
            if field_layout.ty.is_complex() {
                self.write_complex_field_to_bytes(bytes, field_offset, &field_layout.ty, &item.init);
                current_field_idx = field_idx + 1;
                continue;
            }

            match &item.init {
                Initializer::Expr(expr) => {
                    if let Expr::StringLiteral(s, _) = expr {
                        // String literal initializing a char array field
                        // Use chars() to get raw byte values (each char U+0000..U+00FF)
                        if let CType::Array(_, Some(arr_size)) = &field_layout.ty {
                            let s_chars: Vec<u8> = s.chars().map(|c| c as u8).collect();
                            for (i, &b) in s_chars.iter().enumerate() {
                                if i >= *arr_size { break; }
                                if field_offset + i < bytes.len() {
                                    bytes[field_offset + i] = b;
                                }
                            }
                            if s_chars.len() < *arr_size && field_offset + s_chars.len() < bytes.len() {
                                bytes[field_offset + s_chars.len()] = 0;
                            }
                        }
                    } else {
                        let val = self.eval_const_expr(expr).unwrap_or(IrConst::I64(0));
                        let field_ir_ty = IrType::from_ctype(&field_layout.ty);
                        if let (Some(bit_offset), Some(bit_width)) = (field_layout.bit_offset, field_layout.bit_width) {
                            self.write_bitfield_to_bytes(bytes, field_offset, &val, field_ir_ty, bit_offset, bit_width);
                        } else {
                            self.write_const_to_bytes(bytes, field_offset, &val, field_ir_ty);
                        }
                    }
                }
                Initializer::List(sub_items) => {
                    // Nested struct/union: recurse if the field is a struct type
                    if let Some(sub_layout) = self.get_struct_layout_for_ctype(&field_layout.ty) {
                        self.write_struct_init_to_bytes(bytes, field_offset, sub_items, &sub_layout);
                    } else {
                        // Array field or other nested init: try to write elements sequentially
                        if let CType::Array(ref elem_ty, _) = field_layout.ty {
                            let elem_ir_ty = IrType::from_ctype(elem_ty);
                            let elem_size = elem_ty.size();
                            for (i, sub_item) in sub_items.iter().enumerate() {
                                if let Initializer::Expr(expr) = &sub_item.init {
                                    let val = self.eval_const_expr(expr).unwrap_or(IrConst::I64(0));
                                    self.write_const_to_bytes(bytes, field_offset + i * elem_size, &val, elem_ir_ty);
                                }
                            }
                        } else if let Some(first) = sub_items.first() {
                            if let Initializer::Expr(expr) = &first.init {
                                let val = self.eval_const_expr(expr).unwrap_or(IrConst::I64(0));
                                let field_ir_ty = IrType::from_ctype(&field_layout.ty);
                                self.write_const_to_bytes(bytes, field_offset, &val, field_ir_ty);
                            }
                        }
                    }
                }
            }

            current_field_idx = field_idx + 1;

            // For unions with flat init, only the first member can be initialized.
            // Designated inits can overwrite (last designator wins).
            if layout.is_union && designator_name.is_none() {
                break;
            }
        }
    }
}
